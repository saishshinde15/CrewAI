{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAvxXI+bB6w5GDgPMudZZw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saishshinde15/CrewAI/blob/main/Website_RAG_Without_Langchin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "SYqIN52pRks7",
        "outputId": "7b590139-e564-46f7-9a9c-c853886eabde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crewai in /usr/local/lib/python3.11/dist-packages (0.100.1)\n",
            "Collecting crewai_tools\n",
            "  Downloading crewai_tools-0.33.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.4.4)\n",
            "Requirement already satisfied: auth0-python>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from crewai) (4.8.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n",
            "Requirement already satisfied: chromadb>=0.5.23 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.6.3)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.1.8)\n",
            "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.7.2)\n",
            "Requirement already satisfied: json-repair>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.36.0)\n",
            "Requirement already satisfied: json5>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.10.0)\n",
            "Requirement already satisfied: jsonref>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.1.0)\n",
            "Requirement already satisfied: litellm==1.59.8 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.59.8)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.61.1)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.30.0)\n",
            "Requirement already satisfied: pdfplumber>=0.11.4 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.11.5)\n",
            "Requirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.10.6)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.0.1)\n",
            "Requirement already satisfied: pyvis>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.3.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai) (2024.11.6)\n",
            "Requirement already satisfied: tomli-w>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.2.1)\n",
            "Requirement already satisfied: uv>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.5.30)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.59.8->crewai) (3.11.12)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.59.8->crewai) (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.59.8->crewai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.59.8->crewai) (3.1.5)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.59.8->crewai) (4.23.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.59.8->crewai) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm==1.59.8->crewai) (0.21.0)\n",
            "Collecting docker>=7.1.0 (from crewai_tools)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting embedchain>=0.1.114 (from crewai_tools)\n",
            "  Downloading embedchain-0.1.126-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai_tools)\n",
            "  Downloading lancedb-0.19.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting pyright>=1.1.350 (from crewai_tools)\n",
            "  Downloading pyright-1.1.393-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pytube>=15.0.0 (from crewai_tools)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools) (2.32.3)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.10.1)\n",
            "Requirement already satisfied: urllib3>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.3.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.12.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.51b0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (32.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.10.15)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (4.12.3)\n",
            "Collecting chromadb>=0.5.23 (from crewai)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading cohere-5.13.12-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (1.79.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (0.3.17)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_cohere-0.3.5-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.37 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading mem0ai-0.1.48-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (2.0.37)\n",
            "Collecting tiktoken>=0.7.0 (from litellm==1.59.8->crewai)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tokenizers (from litellm==1.59.8->crewai)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Requirement already satisfied: jiter<0.9,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.8.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.27.2)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai_tools)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pylance==0.23.0 (from lancedb>=0.5.4->crewai_tools)\n",
            "  Downloading pylance-0.23.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai_tools) (24.2)\n",
            "Requirement already satisfied: pyarrow>=14 in /usr/local/lib/python3.11/dist-packages (from pylance==0.23.0->lancedb>=0.5.4->crewai_tools) (17.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.22.0->crewai) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (1.30.0)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (5.29.3)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.22.0->crewai) (0.51b0)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (10.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber>=0.11.4->crewai) (3.4.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai_tools)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.0.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai_tools) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai_tools) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.59.8->crewai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.59.8->crewai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.59.8->crewai) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.59.8->crewai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.59.8->crewai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.59.8->crewai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.59.8->crewai) (1.18.3)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai_tools) (2.6)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (1.2.0)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->crewai) (1.17.2)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb>=0.5.23->crewai) (0.45.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (1.26.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.0.7)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai_tools) (5.5.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.23.0->litellm==1.59.8->crewai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm==1.59.8->crewai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.59.8->crewai) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.59.8->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.59.8->crewai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.59.8->crewai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.59.8->crewai) (0.22.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.9)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (0.3.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (0.3.5)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (0.9.0)\n",
            "Collecting langchain-core<0.4.0,>=0.3.33 (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (2.7.1)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->embedchain>=0.1.114->crewai_tools) (1.0.0)\n",
            "Collecting pytz<2025.0,>=2024.1 (from mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading qdrant_client-1.13.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (25.1.24)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.13.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.51b0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.23->crewai) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.23->crewai) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (3.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain>=0.1.114->crewai_tools) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.59.8->crewai) (0.28.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (14.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.59.8->crewai) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.59.8->crewai) (2024.10.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (1.33)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (2025.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.3.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Downloading crewai_tools-0.33.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.9/542.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.126-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lancedb-0.19.0-cp39-abi3-manylinux_2_28_x86_64.whl (32.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.3/32.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.23.0-cp39-abi3-manylinux_2_28_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.393-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.13.12-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.3.5-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.48-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.3/91.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qdrant_client-1.13.2-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: schema, pytz, types-requests, pytube, pysbd, pypdf, portalocker, nodeenv, mypy-extensions, marshmallow, Mako, hyperframe, httpx-sse, hpack, grpcio-tools, fastavro, deprecation, typing-inspect, tiktoken, pyright, pylance, h2, gptcache, docker, alembic, tokenizers, langsmith, lancedb, dataclasses-json, qdrant-client, langchain-core, cohere, mem0ai, langchain-text-splitters, langchain-openai, langchain, langchain-community, chromadb, langchain-experimental, langchain-cohere, embedchain, crewai_tools\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.8.0\n",
            "    Uninstalling tiktoken-0.8.0:\n",
            "      Successfully uninstalled tiktoken-0.8.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.6\n",
            "    Uninstalling langsmith-0.3.6:\n",
            "      Successfully uninstalled langsmith-0.3.6\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.33\n",
            "    Uninstalling langchain-core-0.3.33:\n",
            "      Successfully uninstalled langchain-core-0.3.33\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.17\n",
            "    Uninstalling langchain-0.3.17:\n",
            "      Successfully uninstalled langchain-0.3.17\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.6.3\n",
            "    Uninstalling chromadb-0.6.3:\n",
            "      Successfully uninstalled chromadb-0.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.2 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.9 alembic-1.14.1 chromadb-0.5.23 cohere-5.13.12 crewai_tools-0.33.0 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 embedchain-0.1.126 fastavro-1.10.0 gptcache-0.1.44 grpcio-tools-1.70.0 h2-4.2.0 hpack-4.1.0 httpx-sse-0.4.0 hyperframe-6.1.0 lancedb-0.19.0 langchain-0.3.18 langchain-cohere-0.3.5 langchain-community-0.3.17 langchain-core-0.3.34 langchain-experimental-0.3.4 langchain-openai-0.2.14 langchain-text-splitters-0.3.6 langsmith-0.1.147 marshmallow-3.26.1 mem0ai-0.1.48 mypy-extensions-1.0.0 nodeenv-1.9.1 portalocker-2.10.1 pylance-0.23.0 pypdf-5.3.0 pyright-1.1.393 pysbd-0.3.4 pytube-15.0.0 pytz-2024.2 qdrant-client-1.13.2 schema-0.7.7 tiktoken-0.7.0 tokenizers-0.20.3 types-requests-2.32.0.20241016 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chromadb",
                  "pytz",
                  "tiktoken",
                  "tiktoken_ext"
                ]
              },
              "id": "f711a77ec5fe4b1fab8402188b65435f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install crewai crewai_tools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM, Agent, Crew, Process, Task\n",
        "from crewai.knowledge.source.crew_docling_source import CrewDoclingSource\n",
        "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
        "from crewai_tools import WebsiteSearchTool"
      ],
      "metadata": {
        "id": "-h4iZBoeVWxo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_api=userdata.get('gemini_main')"
      ],
      "metadata": {
        "id": "qgolMp6nbkHO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "gemini_api = userdata.get('gemini_main')\n",
        "\n",
        "# Set the GOOGLE_API_KEY environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = gemini_api\n"
      ],
      "metadata": {
        "id": "v1XJmVlurCaU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"gemini/gemini-2.0-flash-lite-preview-02-05\",\n",
        "    temperature=0.7,\n",
        "    api_key=gemini_api,\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "-TNSrnIUa3wk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.call(\"What is the capital of France?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8f2OZlC6cUta",
        "outputId": "21962ab5-8279-4ae7-d9b0-ffd5427f4ecd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of France is **Paris**.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import WebsiteSearchTool"
      ],
      "metadata": {
        "id": "NZWFh5v_pFuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import WebsiteSearchTool\n",
        "\n",
        "tool = WebsiteSearchTool(\n",
        "    #website='https://docs.phidata.com/workflows/introduction',  # Limits search to this website\n",
        "    config={\n",
        "        \"llm\": {\n",
        "            \"provider\": \"google\",  # Use Google's LLM service\n",
        "            \"config\": {\n",
        "                \"model\": \"gemini/gemini-2.0-flash-lite-preview-02-05\",\n",
        "\n",
        "            },\n",
        "        },\n",
        "        \"embedder\": {\n",
        "            \"provider\": \"google\",  # Use Google's embedding service\n",
        "            \"config\": {\n",
        "                \"model\": \"models/embedding-001\",\n",
        "                \"task_type\": \"retrieval_document\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "n4qrmAB9pXIJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(\n",
        "    role=\"Phi Data Master\",\n",
        "    goal=\"You know everything about the Phi Data Agents.\",\n",
        "    backstory=\"\"\"You are a master at understanding Phi Data Agents and their content.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        "    tools=[tool]\n",
        ")"
      ],
      "metadata": {
        "id": "gVBUIAVJdyz1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = Task(\n",
        "    description=\"Do a deep search on the Phi Data according to the users: {question} in detail.\",\n",
        "    expected_output=\"A structured output with all the details in the paragragh and at the bottom , give the source url of the paper\",\n",
        "    agent=agent,\n",
        "    output_file='DeepSearch.md'\n",
        ")"
      ],
      "metadata": {
        "id": "1b8KxTGmgpQT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    verbose=True,\n",
        "    process=Process.sequential\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8mKgkFuhS67",
        "outputId": "80cb208b-f033-4d50-b115-91d8e1cb15bf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(\n",
        "    inputs={\n",
        "        \"question\": \"What does workflow determine in PhiData?\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jFBvhuWFluBF",
        "outputId": "3b88068e-7dd4-4f5a-b12c-267dbc5db298"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPhi Data Master\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mDo a deep search on the Phi Data according to the users: What does workflow determine in PhiData? in detail.\u001b[00m\n",
            "\u001b[91m \n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: 404 Client Error: Not Found for url: https://www.microsoft.com/en-us/research/project/phi-data/.\n",
            " Tool Search in a specific website accepts these inputs: Tool Name: Search in a specific website\n",
            "Tool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search a specific website', 'type': 'str'}, 'website': {'description': 'Mandatory valid website URL you want to search on', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to semantic search a query from a specific URL content.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPhi Data Master\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch in a specific website\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"workflow PhiData\\\", \\\"website\\\": \\\"https://www.microsoft.com/en-us/research/project/phi-data/\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: 404 Client Error: Not Found for url: https://www.microsoft.com/en-us/research/project/phi-data/.\n",
            " Tool Search in a specific website accepts these inputs: Tool Name: Search in a specific website\n",
            "Tool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search a specific website', 'type': 'str'}, 'website': {'description': 'Mandatory valid website URL you want to search on', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to semantic search a query from a specific URL content..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Search in a specific website]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inserting batches in chromadb: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPhi Data Master\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch in a specific website\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"Phi Data workflow\\\", \\\"website\\\": \\\"https://www.microsoft.com/en-us/research/\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "Relevant Content:\n",
            "Microsoft Research – Emerging Technology, Computer, and Software Research Skip to main content Pause video Microsoft Research AI meets materials discovery: The vision behind MatterGen and MatterSim Learn more Featured Podcasts Feb 10 Ideas: Building AI for population-scale systems with Akshay Nambi Blogs Feb 11 ExACT: Improving AI agents’ decision-making via test-time compute scaling Publication Publications Feb 1 QURE: AI-assisted and Automatically Verified UDF Inlining News Nov 21 ACM MobiCom Best Community Paper Award Publications Mar 30 TUNA: Tuning Unstable and Noisy Cloud Applications Publications Feb 1 Triangle: Empowering Incident Triage with Multi-LLM-Agents Videos Feb 6 Attestations over TLS 1.3 and ZKP Publications Feb 1 Towards Efficient Large Multimodal Model Serving Blogs Feb 5 Advances to low-bit quantization enable LLMs on edge devices Publication Publications Feb 2 Emancipatory Information Retrieval News Jan 7 Microsoft announces US $3bn investment over two years in India cloud and AI infrastructure to accelerate adoption of AI, skilling and innovation Loading Opens in a new tab Follow us: Follow on X Like on Facebook Follow on LinkedIn Subscribe on Youtube Follow on Instagram Subscribe to our RSS feed Share this page: Share on X Share on Facebook Share on LinkedIn Share on Reddit\n",
            "\n",
            "� �?� �;�5�Z�߽�i1�k�A�]6� �-\u0015แđJ�\u0000�\u000e�~�gE�6�U�\u0004z�@ 3�\u0000�T�q�O�}5_,�\"�G�L�=�li<�9�q�\u0006�e\u0000 Q_SP\u0007�X�\u0000�KG�ێ>�[�9�\u00156�'�+�iM^7�h�\u0019 Y.e_@�T�\u0000�^�K�~\u0005�4�Wl�Y�%S�\u000f̚\u0000�(�\u0000+ ş�&�\u000f�\u0000�m[\u0015\u0005�7�7\u0016w Z �)\u0014 eX`�c@  �\u0012�\u0000��__�\u0015�(�}_K�w�s \u0001�J� �F5�\u0001_'|^�ou� vmR�\u0006m\u000e�B�\u000e-ܜ�g�N:�ƣ�\bn� �\u0019\u0014�\"�V\u0007�\u0007�(\u0003�\u0005~Ђ�M�6w\u0017/ �[�l3� 7�\u0011�\u000f>�뵮�,6N�\u0016�yqvF\u0011�c�O�\u0012~�}k�\u0004� T�Of9\"�m�e`�~\u0000UK/�6�\u0007�w�\u000fܞ�\u0000�S�\u0007�z �~)x�R\u0019湹�̼�u�!S�\u0018\u0003\u0001}�\u0015�\u0016�Zh\u001a%�b�m�\"\u0011 =N;�rrO�H�4�\u0002�l�\u0018,헟.\u0014�O�>皿@ �ď�&� �\u0000�|� �>\u0000�\u0000�Q�&�B�Դ�M_M�ӯ�m.c1K ⻔�\u0011�A �s�\u0007�O\b�_T]KF�>�x�PI�_�a�Ҁ:�(� (� ��G�D�'� �M�+\u0017Ğ\u0013�<_g\u0015�e�!�D�^<6\b�P�К\u0000�\u0007�f�e�7�46p�MҬ�\u0018�E�b;� �kпh�\u0016k$\u001a�yox\u0006 �\u0015d�\u0002>�k�<9�\u0003�v�6�&�-�m�!�\u000eq�cڹ]o�w�5�[)� �.�'� � \u0000� �?�z�o�-|�)%�\u0016ES�b�8'�G?�[�ǉ|A\u0006�}\u0003.�a �\u0017 J�*�\u0003�c�zޕ�\u0013�\u001am�,7�S�s�@�kҭ�\u0018�5 �ơU@�\u0000� \u0000� �}�&�(b�5�\u0000bQϷ�A=�}�$�r\"�0*� �\u0011@ /�2�\u000f�D�,�cb`�\u0002<�A9+�@a�OQ�\u0000�7�3X麝�RDH�>�\u0003[Z�\u0004j� :Z�,�ع�V \u0007�\u0001U�>\b�d�;� 칸��\u0001�:�ω�( [�w�\"�4�>P�Q� OV9�?�a[�k�\u0006K�\u0000� �<7�y�\u0007�])�6�\u0003\u001a�p6�}+7�\u000f<+�ME�M$Z]4f&�O � \u0004�3\u0011� \u0000�?\u000e�о �o�ëB� h>L� \u0015?�>�r\u001a�\u0005k�^h\u0016�+rd�-�S�h\u0003�<%,`�Xj�I�\b�C�\u0000J�?�\u001bh�|�xkL�\u0017N�V�*�\u0000� �}2G�Һ �\u0000g\u0006J�W�v;� �\u0000 Bj� �t�,�W̧ ]�\u0012?\u0010�A�h\u0003ž\u000ex&�>3�e�\u0000�4�k� <�w*\u0003ܓ�}\u0007�g�J�;[;x�\u001bR(�*�\u0000p*j\u0000�\u000f� �oe�^�l�\u0019\u0006o�@�\u0000X�u� �q�|?�ݪxF�-'S�:�\u0017�\u0017϶XW� �=\u0001�+�E�'�/�Z�ٌN�ᏹ\u0006�9H�\u0000h�\u00074[�XF�Dg�\u0000g�Mc�X�tM\u0006y �/d\b\u0007�\u0005s�V�<\u001ad�/u�?�. �li\u0004| �:�[�:�7s3�aO�(\u0002�\u001ak^6�u�;�X�0�\u001a�$�$ר�\u0016vV�u�[YZ�mn�v(c\b�\u0003� (� (� (� �>*k�<\u0001{�iS\bo � �P0�A\u0004 �\u0012+�c�X�e�Cwk&7�:\u0007V�@ \u0017�i�*k�\u0013o zk\u0019\u0006\u000f�\u0001��Uџ�+�=�X-�ϳǟ�\u000f\u0015� � �\u0017M2k6=M�Á�1 ~\u0002�?� �w۵�wϋ �.�<�ǿ �\u000f\u0013i�iZ-�i�3\u0002�JϺiT�^8P{�$�~\u000e�0�&�m�v�\u0016�j�D�\u0017 jpr\u0015Gu�Sӌz�t_�>\u0007�%Y�I�d�r �C(�\u0000�O�Wz�\u0011B�\u0000\u0006\u0000\u0014\u0000�QE\u0000|�s�׃|E&�c �\u0000b�d�D @�}0~�\u0006�o\u0007~�i�Y�K�/�-B� R3�A^�uko}k%�\u0011Oo*�)P2� �k�O�\b�gib�[K�\u000e\u001b �\u0000q^5�\"�Ҧ�\u0013L�\u001a� у�b�y�$cҹ_�\u000en|S�\bu�\u0019t[)\u0004�qq 9\b=Fyo�;װi?\u0001�\u000f�N�Kow�\u00159 y>W>�\u0002�5�6�Z[�om p�\u001a�H�P�\u0001�\u0014\u0001%Eum �֗1�O\u001bG\"7FR0A� KE\u0000|o�o\u0007�\u0000 �^�\u0003J�,�v�|�\u0000r9�w �C^�7I�O�<C�z�U�+�^ɩ�V\u001aՄ�:�7v�}�@� z�{�7s\u0019!�ҲRs�܂�V?�\u0000y�o�M&m\u0017�֓�Y� �\u0017\u0013�$�;�\u0000�99 qV�\u0004|9�v�\u0003Gi\u0006M�8� f?�; �: �/\u0004h� q� o�C�7�y� �@ \u0010k�U\u0014*�\u0014\n",
            "\n",
            "'\u0015\u0014�\u0014QVy�E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0015�=B}+×�ч�\bK�  >�u�(nڕN\u000esP[� J+ż\u0015�_\u0010]x�K�n� /\u0004�\u0018�\u0015�50�;1� �*�F� (�<�톩s�4\u0011K-�a�`�@� �C� fo\u0005�.k�f+�\u0014�\u0018� \u000e�|�\u0003��~}Z�\u0019xQ<W�n'�.!}�HFGL\u0010G�r[� 1�:\u0010�׍��w؋�1�v�z�\b�Fq � \u0012\u000e�\u0007�y\u000e�x�|]l�kw �w\u0001�\u0004x �\u0011Aq<�+qu8 J.\u0015\u0014s�G4�-f4p5j� hK�₊(�O\b(�\u0000�k��X�U� �\u0010QE\u0015�\u0001E\u0014P\u0001^k�IM�\u0000�w�\u0000F �_�\u0000�Jo�\u0000� �0P\u0007A�I�?�/�]Ur� �xs�\"�U�P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0001E\u0014P\u0007�~�_�(� ��[W� �\u0000� �\u0000�\u000f�K�E  �j�7�AV�?�\u0011@\u0016�\u0000(�\u0000+�3ȟi�\u0000_�\u0000�D�;�\u0000\"}��0�Ɖ� �<{Cѥ�\u0006�\u0006� �\u0014�ø8\u001bT�o�{�<&�\u0013�3�\u0013>�d\u0003�\u0000\u0003�Z�;K۝:�.�xgL�\u000e\b� �j�i�:�pu\u00162�\u0016r0\u0011� R?�1�c%�O�j�\u0000;�=FZ�\u000f�i�֤?\u0015l�+�\u000e�\u0014�Xc�u�q�I\u0018�:��e�\"�-�4�K\u0015�B,�\u0001�z�\u0015�1Q̥ \u0013�>�;�\u0014QVy�E\u0014P\u0007�G�2E �BЅ�$\u0003�{\u0013�/YO\u0019ZI\u0015�) �3�U �Aϯ�W�Q�å7;�P�G ,:�wV�W�Mb9�d�1�$)�>�UW�C� n �>t�a�J �o\u000e� �e|�Us�5�E\u0015� �\u0015 �u'�'.�E\u0014U\u0012\u0014QE\u0000\u0014QE\u0000\u0014QE\u0000\u0014QE\u0000\u0004�d�8<[�\u0002�;�j�R\u0015�5�<Bx$�\u0001ԩ �yퟀ�\u0018�X�\"\u0016Ѹc*�,\u0001�=k�٫�:p�K�JݏF�+� (� �\u0001�2j�y2Dm�r�VnT\u0013�zףQX֡ �)t6�\u0016�:�\u0010�\b�RHE �p1RQElb\u0014QQEuo;�C<R: :�W뎔\u0005�Ԗ�H�YJ\u0010�8⤢�G�n�<A $\u0017 t�\u0002�I�u�Q�|:�N�:q8�]�լ\u0014QEt �E\u0014P\u00075�MZ�J�!�\u001b\u0018�i6�r�\u0019�?ҩx Z�Z�F�cP� u\u0019= �\u0000֮� �\u001a �X�ȦYi�t&+Kt� � :�Z�t�:ʧ6�Z� &�և6�,FR�\"F\u000e71�3�W7࿈�]M�4�b�hؕlu\u0007=�W�֚�6�x\u001bʓ\u0007r�2�Џz�4�\u0000 �Ix�sr�Q^@\u0000E=p\u0007z�+luP�\u0005`檧�:~�^�[E\u0014U�`QE\u0014\u0000QE\u0014\u0000QE\u0014\u0000QE\u0014\u0000QE\u0014\u0000QE\u0014\u0000QE\u0014\u0001�hZ^�\u0000h�rc� �늻\u0004\u0010�[đE\u0018ڈ�\u0001G�\u0015%\u0014X�Rn* �\u0005\u0014QA!E\u0014P\u0001E\u0014P\u0001Q�k7�Z�=&�\u0000q�\u0000|?��\u0000?�?�ƾ� �\u0017�Wµ�U�zC�\u0000*�t1�Ԗ�*\u0015�{�Y�3�F n Qֹ�oc[�QE5�H�GTE\u0019,�\u0000 C Ex�\u0000ŝ]5�Z�+�G!U�%� d�^�m:�ZCp�\u0015�=@ 5ߌ�k�\u0019U_\u0011�G\u0013N�j h�x�m丞E�\u0018Ի� \u0005\u0003�5�t$۲$�SB�/�F�\u001b� �.9 �Vf�\u0007]�M�;\u0004�\u0012c�\u0000.�R�7�+a�'\u0019}̎\b!� �\"�1�\u0011\u0006\u0002�@+?P�捪�%�oq2p לz Q�J+HT�7x;? �IO�EUE �\u0005\u0003\u0000\u0001�\u0014�QP0�_�6z]�o �i\u001b �>¼�Ŀ\u0015d�=�\u0019�O\u0006�Q� �W�B�p�J�ݠ�иS�;�\u0011x�K�\u0019�}�\u0019Kx�v�\u0000\u0001�k�M�mSĮc�d\u000f�m\u0019�\u0000��Ջ\u00147�Ρ�5�f�wf>�k�<1�\u00186]�&�C�/�ǿ�q�j4p�\u0005�Q�_�:�i�W�\u000f�\u0005�%�<1�\u0016`�d /�\u0004\u0011�~b�þ\u0014�<5o�-Ӱė\u0012r� ¶�!�c�\u0015 Q�U\u0018\u0000z\u0001N�/\u0017�U�i�{�R�\u0014QEp\u0019\u0005\u0014Tr�\u0014 \u001aiR0N\u0001v\u0003?�\u0000\u0013�\u001a�Q\u0011 )B\u0010� W�n�<A $\u0017 t�\u0002�I�u�dt�\u0011�\u0013�^ �<�B]\u0001\u0019�>ï�،:�ԛ�%iA�qWr�ԯ\u001b�j�x�+�&y�*�Rʧ� <�Qx+ƾ �e�p�9I p>^ �1� �+�kM*�Q�┤�3�}k�>� IdIAb�'�D'�\u0007�ں�(�\u0012�ת�U�F�wp�7�m[F{\u001b=:g�I�A�1\u0007\u001bA�􊥩i:~�n �m\"� �H: Pz�W�C\u0011\u001a�c�\u0015�S�Jn0vg-�\u001a� E̯o(E�\u0017\u0004g\u0007ԏ�+�6\u0016�m�Z�[�\u0004 �  �Q�N�yT� X�*�% j2wh(�5 (� (� (�\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPhi Data Master\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Workflows in the context of Phi Data (assuming a data processing or machine learning context) determine the sequence of operations performed on data. They define the steps from data ingestion to analysis, model training, deployment, and monitoring.\n",
            "\n",
            "Here's a breakdown of what workflows determine:\n",
            "\n",
            "1.  **Data Ingestion:** This determines how data enters the system, including its source (databases, files, APIs, etc.), format, and any initial processing steps (e.g., cleaning, validation).\n",
            "2.  **Data Transformation:** Defines how the data is manipulated. This includes cleaning, filtering, joining, aggregating, and feature engineering.\n",
            "3.  **Model Training (if applicable):** Specifies the process of training machine learning models, including data splitting, model selection, hyperparameter tuning, and evaluation.\n",
            "4.  **Model Deployment (if applicable):** Outlines the steps to make the model available for predictions, including infrastructure setup, API creation, and integration with other systems.\n",
            "5.  **Data Analysis/Reporting:** Determines how data is analyzed and presented, including generating reports, visualizations, and dashboards.\n",
            "6.  **Monitoring:** Sets up processes to track the performance of the workflow, including data quality, model accuracy, and system health. This allows for the identification of issues and the optimization of the workflow.\n",
            "7.  **Automation:** Workflows often automate these steps, reducing manual effort and improving efficiency. They can be triggered by events, schedules, or other conditions.\n",
            "8.  **Dependencies:** Workflows define dependencies between tasks. For instance, data transformation must complete before model training can begin.\n",
            "9.  **Error Handling:** Specifies how the workflow handles errors and exceptions, including logging, retries, and notifications.\n",
            "10. **Version Control:** Workflows benefit from version control, allowing for tracking changes, collaboration, and the ability to revert to previous states.\n",
            "\n",
            "Since I could not find specific information on a \"Phi Data\" platform, this explanation provides a general overview of how workflows operate in a data-centric environment.\n",
            "\n",
            "Source: General Knowledge of Data Science and Machine Learning Workflow principles\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(\"DeepSearch.md\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "7RVCdjj2y8wV",
        "outputId": "40827570-f354-405e-b4d9-0e9295013351"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Workflows in the context of Phi Data (assuming a data processing or machine learning context) determine the sequence of operations performed on data. They define the steps from data ingestion to analysis, model training, deployment, and monitoring.\n\nHere's a breakdown of what workflows determine:\n\n1.  **Data Ingestion:** This determines how data enters the system, including its source (databases, files, APIs, etc.), format, and any initial processing steps (e.g., cleaning, validation).\n2.  **Data Transformation:** Defines how the data is manipulated. This includes cleaning, filtering, joining, aggregating, and feature engineering.\n3.  **Model Training (if applicable):** Specifies the process of training machine learning models, including data splitting, model selection, hyperparameter tuning, and evaluation.\n4.  **Model Deployment (if applicable):** Outlines the steps to make the model available for predictions, including infrastructure setup, API creation, and integration with other systems.\n5.  **Data Analysis/Reporting:** Determines how data is analyzed and presented, including generating reports, visualizations, and dashboards.\n6.  **Monitoring:** Sets up processes to track the performance of the workflow, including data quality, model accuracy, and system health. This allows for the identification of issues and the optimization of the workflow.\n7.  **Automation:** Workflows often automate these steps, reducing manual effort and improving efficiency. They can be triggered by events, schedules, or other conditions.\n8.  **Dependencies:** Workflows define dependencies between tasks. For instance, data transformation must complete before model training can begin.\n9.  **Error Handling:** Specifies how the workflow handles errors and exceptions, including logging, retries, and notifications.\n10. **Version Control:** Workflows benefit from version control, allowing for tracking changes, collaboration, and the ability to revert to previous states.\n\nSince I could not find specific information on a \"Phi Data\" platform, this explanation provides a general overview of how workflows operate in a data-centric environment.\n\nSource: General Knowledge of Data Science and Machine Learning Workflow principles"
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EEnkh-NdzKfw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}