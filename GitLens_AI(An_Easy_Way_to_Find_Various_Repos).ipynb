{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8accvIjilxIY510ck8DrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saishshinde15/CrewAI/blob/main/GitLens_AI(An_Easy_Way_to_Find_Various_Repos).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opwaaAIhe42I",
        "outputId": "f7900f5a-9722-4673-ed21-94a42d144cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting crewai\n",
            "  Downloading crewai-0.86.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.14 (from langchain-community)\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python>=4.7.1 (from crewai)\n",
            "  Downloading auth0_python-4.7.2-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting chromadb>=0.5.18 (from crewai)\n",
            "  Downloading chromadb-0.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai) (8.1.7)\n",
            "Collecting crewai-tools>=0.17.0 (from crewai)\n",
            "  Downloading crewai_tools-0.25.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.7.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting json-repair>=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.35.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm>=1.44.22 (from crewai)\n",
            "  Downloading litellm-1.56.9-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.57.4)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.10/dist-packages (from crewai) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.29.0)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.10.3)\n",
            "Collecting python-dotenv>=1.0.0 (from crewai)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pyvis>=0.3.2 (from crewai)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.10/dist-packages (from crewai) (2024.11.6)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.2.1)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.5.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: cryptography<44.0.0,>=43.0.1 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (2.10.1)\n",
            "Requirement already satisfied: urllib3<3.0.0,>=2.0.7 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (2.2.3)\n",
            "Collecting build>=1.0.3 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading posthog-3.7.5-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (1.68.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (13.9.4)\n",
            "Requirement already satisfied: beautifulsoup4>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from crewai-tools>=0.17.0->crewai) (4.12.3)\n",
            "Collecting docker>=7.1.0 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting docx2txt>=0.8 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting embedchain>=0.1.114 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading embedchain-0.1.126-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading lancedb-0.17.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting linkup-sdk>=0.2.1 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading linkup_sdk-0.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pyright>=1.1.350 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading pyright-1.1.391-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: pytest>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from crewai-tools>=0.17.0->crewai) (8.3.4)\n",
            "Collecting pytube>=15.0.0 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting scrapegraph-py>=1.8.0 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading scrapegraph_py-1.8.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting selenium>=4.18.1 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting serpapi>=0.1.5 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting spider-client>=0.1.25 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading spider-client-0.1.25.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting weaviate-client>=4.9.6 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading weaviate_client-4.10.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (3.1.4)\n",
            "Requirement already satisfied: jiter<0.9,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (0.8.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (2.27.1)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.2)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting httpx>=0.27.0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.44.22->crewai) (8.5.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.44.22->crewai) (4.23.0)\n",
            "Collecting tiktoken>=0.7.0 (from litellm>=1.44.22->crewai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->crewai) (1.2.15)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.29.0->opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->crewai) (0.50b0)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber>=0.11.4->crewai) (11.0.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber>=0.11.4->crewai) (3.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (4.0.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.13.3->crewai) (1.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.12.3->crewai-tools>=0.17.0->crewai) (2.6)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->crewai) (1.17.0)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting chromadb>=0.5.18 (from crewai)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading cohere-5.13.5-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (1.74.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading langchain_cohere-0.3.4-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langsmith<0.3,>=0.1.125 (from langchain-community)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.37 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading mem0ai-0.1.39-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting tiktoken>=0.7.0 (from litellm>=1.44.22->crewai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tokenizers (from litellm>=1.44.22->crewai)\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb>=0.5.18->crewai)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.18->crewai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.18->crewai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.44.22->crewai) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (0.22.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "INFO: pip is looking at multiple versions of lancedb to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting lancedb>=0.5.4 (from crewai-tools>=0.17.0->crewai)\n",
            "  Downloading lancedb-0.17.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting pylance==0.20.0 (from lancedb>=0.5.4->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading pylance-0.20.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pyarrow>=14 in /usr/local/lib/python3.10/dist-packages (from pylance==0.20.0->lancedb>=0.5.4->crewai-tools>=0.17.0->crewai) (17.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.5.18->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.18->crewai) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.18->crewai) (1.13.1)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.18->crewai)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.5.18->crewai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.5.18->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai-tools>=0.17.0->crewai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai-tools>=0.17.0->crewai) (1.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb>=0.5.18->crewai) (3.0.0)\n",
            "Collecting trio~=0.17 (from selenium>=4.18.1->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium>=4.18.1->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting ijson (from spider-client>=0.1.25->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm>=1.44.22->crewai) (0.27.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb>=0.5.18->crewai) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai) (14.1)\n",
            "Collecting validators==0.34.0 (from weaviate-client>=4.9.6->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client>=4.9.6->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting grpcio-tools<2.0.0,>=1.66.2 (from weaviate-client>=4.9.6->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client>=4.9.6->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading grpcio_health_checking-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (4.9)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (2.19.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (1.25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (2.0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.44.22->crewai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.44.22->crewai) (2024.10.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (0.9.0)\n",
            "Collecting openai>=1.13.3 (from crewai)\n",
            "  Downloading openai-1.59.3-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.18->crewai) (0.1.2)\n",
            "Requirement already satisfied: pytz<2025.0,>=2024.1 in /usr/local/lib/python3.10/dist-packages (from mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (2024.2)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading qdrant_client-1.12.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium>=4.18.1->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium>=4.18.1->crewai-tools>=0.17.0->crewai) (1.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.18->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.18->crewai) (1.3.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (1.62.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (0.13.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (1.6.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai) (2024.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (0.6.1)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.37->embedchain>=0.1.114->crewai-tools>=0.17.0->crewai)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai-0.86.0-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading auth0_python-4.7.2-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai_tools-0.25.8-py3-none-any.whl (514 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.9/514.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading instructor-1.7.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.35.0-py3-none-any.whl (19 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.56.9-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.29.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.1.0-py3-none-any.whl (6.4 kB)\n",
            "Downloading uv-0.5.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.126-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lancedb-0.17.0-cp39-abi3-manylinux_2_28_x86_64.whl (29.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.9/29.9 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.20.0-cp39-abi3-manylinux_2_28_x86_64.whl (33.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linkup_sdk-0.2.1-py3-none-any.whl (8.0 kB)\n",
            "Downloading marshmallow-3.23.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.5-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.391-py3-none-any.whl (18 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scrapegraph_py-1.8.0-py3-none-any.whl (14 kB)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading weaviate_client-4.10.2-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cohere-5.13.5-py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.7/250.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.68.1-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.3.4-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.59.3-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.39-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading qdrant_client-1.12.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: docx2txt, pypika, spider-client\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=02ceb1a763720f8453037dc4488caefa97cdf97c993532f54259d9b186059432\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=3b32e0cf13ac5a18f66994b20bac3a728f06d0e06ccab22bc14a58d1a02480f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for spider-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spider-client: filename=spider_client-0.1.25-py3-none-any.whl size=13084 sha256=87121e61b0b2bf6f351566209d76266cee5b09d27156023688b0eec6060507ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/ce/0b/9343ab69b0896f9d7ebb1f66ce3fab63b503b883453a2615d4\n",
            "Successfully built docx2txt pypika spider-client\n",
            "Installing collected packages: sortedcontainers, schema, pypika, monotonic, ijson, durationpy, docx2txt, appdirs, wsproto, validators, uvloop, uvicorn, uv, types-requests, tomli-w, pytube, python-dotenv, pysbd, pyproject_hooks, pypdfium2, pypdf, protobuf, portalocker, parameterized, overrides, outcome, opentelemetry-util-http, nodeenv, mypy-extensions, mmh3, marshmallow, Mako, jsonref, json-repair, jedi, hyperframe, humanfriendly, httpx-sse, httptools, hpack, fastavro, deprecation, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, trio, tiktoken, starlette, serpapi, pyright, pylance, posthog, opentelemetry-proto, httpx, h2, grpcio-tools, grpcio-health-checking, gptcache, docker, coloredlogs, build, alembic, trio-websocket, tokenizers, pyvis, pydantic-settings, pdfminer.six, opentelemetry-exporter-otlp-proto-common, openai, onnxruntime, linkup-sdk, langsmith, lancedb, kubernetes, fastapi, dataclasses-json, authlib, weaviate-client, spider-client, selenium, scrapegraph-py, qdrant-client, pdfplumber, opentelemetry-instrumentation, litellm, langchain-core, instructor, cohere, auth0-python, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mem0ai, langchain-openai, opentelemetry-instrumentation-fastapi, langchain, langchain-community, chromadb, langchain-experimental, langchain-cohere, embedchain, crewai-tools, crewai\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.57.4\n",
            "    Uninstalling openai-1.57.4:\n",
            "      Successfully uninstalled openai-1.57.4\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.2.3\n",
            "    Uninstalling langsmith-0.2.3:\n",
            "      Successfully uninstalled langsmith-0.2.3\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.8 alembic-1.14.0 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.7.2 authlib-1.3.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 cohere-5.13.5 coloredlogs-15.0.1 crewai-0.86.0 crewai-tools-0.25.8 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 docx2txt-0.8 durationpy-0.9 embedchain-0.1.126 fastapi-0.115.6 fastavro-1.10.0 gptcache-0.1.44 grpcio-health-checking-1.68.1 grpcio-tools-1.68.1 h2-4.1.0 hpack-4.0.0 httptools-0.6.4 httpx-0.27.2 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.0.1 ijson-3.3.0 instructor-1.7.2 jedi-0.19.2 json-repair-0.35.0 jsonref-1.1.0 kubernetes-31.0.0 lancedb-0.17.0 langchain-0.3.14 langchain-cohere-0.3.4 langchain-community-0.3.14 langchain-core-0.3.29 langchain-experimental-0.3.4 langchain-openai-0.2.14 langsmith-0.1.147 linkup-sdk-0.2.1 litellm-1.56.9 marshmallow-3.23.3 mem0ai-0.1.39 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 nodeenv-1.9.1 onnxruntime-1.20.1 openai-1.59.3 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-exporter-otlp-proto-http-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-util-http-0.50b0 outcome-1.3.0.post0 overrides-7.7.0 parameterized-0.9.0 pdfminer.six-20231228 pdfplumber-0.11.5 portalocker-2.10.1 posthog-3.7.5 protobuf-5.29.2 pydantic-settings-2.7.1 pylance-0.20.0 pypdf-5.1.0 pypdfium2-4.30.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.391 pysbd-0.3.4 python-dotenv-1.0.1 pytube-15.0.0 pyvis-0.3.2 qdrant-client-1.12.2 schema-0.7.7 scrapegraph-py-1.8.0 selenium-4.27.1 serpapi-0.1.5 sortedcontainers-2.4.0 spider-client-0.1.25 starlette-0.41.3 tiktoken-0.7.0 tokenizers-0.20.3 tomli-w-1.1.0 trio-0.28.0 trio-websocket-0.11.1 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uv-0.5.14 uvicorn-0.34.0 uvloop-0.21.0 validators-0.34.0 watchfiles-1.0.3 weaviate-client-4.10.2 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-community crewai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew, Process,LLM"
      ],
      "metadata": {
        "id": "7ym40xaxe8DW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import ScrapeWebsiteTool,SerperDevTool"
      ],
      "metadata": {
        "id": "0Fp3pWVVgPRb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "serper_api=userdata.get('serper')"
      ],
      "metadata": {
        "id": "A6jNM9Mygx_b"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"SERPER_API_KEY\"] = serper_api\n"
      ],
      "metadata": {
        "id": "9AdEe3Zng87q"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()"
      ],
      "metadata": {
        "id": "LIKB4hZGhZRM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u12VykwCjyy1",
        "outputId": "f4e0ddb0-fcee-453e-c0f2-03790c01ac4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "#llm = ChatGoogleGenerativeAI(\n",
        "   # model=\"gemini-1.5-pro\",\n",
        "   # temperature=0,\n",
        "    #max_tokens=None,\n",
        "    #timeout=None,\n",
        "    #max_retries=2,\n",
        "    #api_key=\"AIzaSyDcpMQzF9mV6KntoNAZenrm-J206-Jczmg\"\n",
        "#)"
      ],
      "metadata": {
        "id": "1ZZh3n2Yj101"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = LLM(\n",
        "    model=\"gemini/gemini-1.5-flash\",\n",
        "    temperature=0.7,\n",
        "    api_key=\"AIzaSyDcpMQzF9mV6KntoNAZenrm-J206-Jczmg\"\n",
        ")"
      ],
      "metadata": {
        "id": "gDyG_jHRlQhq"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "github_agent = Agent(\n",
        "    role=\"GitHub Link Researcher\",\n",
        "    goal=\"Search for and analyze GitHub repositories and related links to the topic {input} \"\n",
        "         \"Try to provide a diverse and structured collection of resources \"\n",
        "         \"for user queries {input}. Ensure the collection contains the most \"\n",
        "         \"starred repositories as well as lesser-known but relevant ones.\",\n",
        "    tools=[search_tool, scrape_tool],\n",
        "    verbose=True,\n",
        "    llm=llm,\n",
        "    backstory=(\n",
        "        \"As a GitHub Link Researcher, you excel at navigating and extracting \"\n",
        "        \"critical information from GitHub and related websites. Your skills \"\n",
        "        \"help identify both popular and hidden-gem repositories that align \"\n",
        "        \"with user queries. By presenting results in a structured and \"\n",
        "        \"categorized format, you empower users with actionable and well-rounded insights.\"\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "WSId7DHZP54p"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_check_agent = Agent(\n",
        "    role=\"Quality Assurance Specialist for GitHub Links\",\n",
        "    goal=\"Recheck and validate the results provided by the GitHub Link Researcher. \"\n",
        "         \"Ensure the selected repositories are the most relevant and provide users \"\n",
        "         \"with the best possible links by performing additional searches and scraping if needed.\",\n",
        "    tools=[search_tool, scrape_tool],\n",
        "    verbose=True,\n",
        "    llm=llm,\n",
        "    backstory=(\n",
        "        \"As a Quality Assurance Specialist for GitHub Links, your role is to ensure \"\n",
        "        \"that the results provided by the GitHub Link Researcher meet the highest standards. \"\n",
        "        \"You re-analyze the results, cross-reference with additional data from the web, \"\n",
        "        \"and confirm their relevance and value. If necessary, you conduct independent \"\n",
        "        \"searches and web scraping to provide an improved and refined collection of resources.\"\n",
        "        \"And if better results are found then prresent them in structured and categorized format.\"\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "6gqPqpF5SxYX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readme_extractor_agent = Agent(\n",
        "    role=\"GitHub Repository ReadMe Extractor and Explainer\",\n",
        "    goal=\"Extract the ReadMe file from each provided GitHub repository link and \"\n",
        "         \"generate a concise, user-friendly explanation of what the repository is about, \"\n",
        "         \"highlighting its purpose and key features. Serve as the final step to enrich \"\n",
        "         \"the output with meaningful summaries.\",\n",
        "    tools=[scrape_tool],\n",
        "    verbose=True,\n",
        "    llm=llm,\n",
        "    backstory=(\n",
        "        \"As the GitHub Repository ReadMe Extractor and Explainer, your role is pivotal \"\n",
        "        \"in translating technical information into accessible insights. You extract ReadMe files \"\n",
        "        \"from GitHub repositories and analyze them to create clear, concise descriptions of each project. \"\n",
        "        \"Your explanations help users understand the relevance and utility of each repository, \"\n",
        "        \"making it easier for them to make informed choices. Your summaries are the final touch \"\n",
        "        \"in delivering a polished and comprehensive output.\"\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "s_yj0zK3Tssx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "github_search_task = Task(\n",
        "    description=(\n",
        "        \"1. Perform a detailed search using the provided input '{input}' \"\n",
        "            \"to identify the most relevant GitHub repositories.\\n\"\n",
        "        \"2. Use the search tool to find repositories with high stars and popularity, \"\n",
        "            \"as well as those that are less popular but still relevant.\\n\"\n",
        "        \"3. Scrape websites if necessary to gather diverse GitHub links \"\n",
        "            \"that align with the given topic or title.\\n\"\n",
        "        \"4. Categorize the results into three groups:\\n\"\n",
        "        \"    - Highly Relevant Links (most starred and popular)\\n\"\n",
        "        \"    - Moderately Relevant Links (relevant but not the most popular)\\n\"\n",
        "        \"    - Hidden Gems (lesser-known but interesting or useful repositories).\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A structured collection of GitHub links categorized as:\\n\"\n",
        "        \"  - Highly Relevant Links\\n\"\n",
        "        \"  - Moderately Relevant Links\\n\"\n",
        "        \"  - Hidden Gems\\n\"\n",
        "        \"Each link should be accompanied by a brief relevance description.\"\n",
        "    ),\n",
        "    agent=github_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "7qj2CBcxWyZJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_check_task = Task(\n",
        "    description=(\n",
        "        \"1. Revalidate the GitHub links provided by the first agent to ensure their quality and relevance.\\n\"\n",
        "        \"2. Use the search tool to cross-check the links against other available repositories online, \"\n",
        "            \"looking for better or more relevant alternatives if necessary.\\n\"\n",
        "        \"3. Utilize the scrape tool to gather additional insights from the web about the provided repositories, \"\n",
        "            \"validating their usefulness and popularity.\\n\"\n",
        "        \"4. Confirm that the categorization into 'Highly Relevant Links,' 'Moderately Relevant Links,' \"\n",
        "            \"and 'Hidden Gems' is accurate and well-justified.\\n\"\n",
        "        \"5. Document any improvements or replacements made to the original list.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A refined collection of GitHub links, ensuring the following:\\n\"\n",
        "        \"  - Links are the most relevant and useful for the given input.\\n\"\n",
        "        \"  - Any adjustments or replacements are clearly noted.\\n\"\n",
        "        \"  - Categorization into 'Highly Relevant Links,' 'Moderately Relevant Links,' \"\n",
        "        \"and 'Hidden Gems' is confirmed as accurate.\"\n",
        "    ),\n",
        "    agent=quality_check_agent,\n",
        "    context=[github_search_task]\n",
        ")\n"
      ],
      "metadata": {
        "id": "V__4fENkXpVU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readme_extraction_task = Task(\n",
        "    description=(\n",
        "        \"1. Extract the ReadMe file from each GitHub repository link provided by the second agent.\\n\"\n",
        "        \"2. Analyze the ReadMe content to understand the repository's purpose, features, and relevance to the given input '{input}'.\\n\"\n",
        "        \"3. Summarize each repository in a concise and user-friendly explanation, highlighting key aspects such as:\\n\"\n",
        "        \"    - Purpose of the repository\\n\"\n",
        "        \"    - Notable features\\n\"\n",
        "        \"    - Potential use cases or applications.\\n\"\n",
        "        \"4. Ensure that repositories without ReadMe files are noted, and their descriptions are inferred using available metadata or alternative sources.\\n\"\n",
        "        \"5. Compile the final output into a structured format, maintaining the categorization into:\\n\"\n",
        "        \"    - Highly Relevant Links\\n\"\n",
        "        \"    - Moderately Relevant Links\\n\"\n",
        "        \"    - Hidden Gems.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A structured and enriched collection of GitHub links with the following details:\\n\"\n",
        "        \"  - Repository link\\n\"\n",
        "        \"  - Category (Highly Relevant, Moderately Relevant, or Hidden Gems)\\n\"\n",
        "        \"  - Brief explanation based on ReadMe content, or inferred description if ReadMe is unavailable.\"\n",
        "        \"The output should be presented as a well structured markdown files with all details\"\n",
        "    ),\n",
        "    agent=readme_extractor_agent,\n",
        "    context=[quality_check_task],\n",
        "    output_file=\"Final_copy.md\"\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "Yp1LELmIYGy5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "github_crew=Crew(\n",
        "    agents=[github_agent,quality_check_agent,readme_extractor_agent],\n",
        "    tasks=[github_search_task,quality_check_task,readme_extraction_task],\n",
        "    process=Process.sequential,\n",
        "    verbose=True\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlpXIamBYzmm",
        "outputId": "f2a13140-2959-4bb9-f886-eb12d30e2cad"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = {\"input\":\"Give me code for finetuning llama 3 model\"}"
      ],
      "metadata": {
        "id": "nbFhQgRjZXsZ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = github_crew.kickoff(inputs=user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j1OiDJsZm7_",
        "outputId": "7ccde86e-8c68-4fe6-c26f-f34cc8101ad2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Link Researcher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92m1. Perform a detailed search using the provided input 'Give me code for finetuning llama 3 model' to identify the most relevant GitHub repositories.\n",
            "2. Use the search tool to find repositories with high stars and popularity, as well as those that are less popular but still relevant.\n",
            "3. Scrape websites if necessary to gather diverse GitHub links that align with the given topic or title.\n",
            "4. Categorize the results into three groups:\n",
            "    - Highly Relevant Links (most starred and popular)\n",
            "    - Moderately Relevant Links (relevant but not the most popular)\n",
            "    - Hidden Gems (lesser-known but interesting or useful repositories).\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Link Researcher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I need to search the internet for GitHub repositories related to fine-tuning the Llama 3 model.  I'll use a broad search initially, then refine it if necessary.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"github llama 3 finetuning\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'github llama 3 finetuning', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'ruslanmv/Meta-Llama3-Fine-Tuning - GitHub', 'link': 'https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning', 'snippet': 'In this repository we present different methods to fine tune a pretrained model. How to Fine Tune Pretrained Models · How to Fine Tune Llama 3 with unsloth.', 'position': 1}, {'title': 'hiyouga/LLaMA-Factory: Unified Efficient Fine-Tuning of 100+ LLMs ...', 'link': 'https://github.com/hiyouga/LLaMA-Factory', 'snippet': \"LLaMA Factory's LoRA tuning offers up to 3.7 times faster training speed with a better Rouge score on the advertising text generation task.\", 'position': 2, 'sitelinks': [{'title': 'README_zh.md', 'link': 'https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md'}, {'title': 'data/README.md', 'link': 'https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README.md'}, {'title': 'examples/README.md', 'link': 'https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/README.md'}, {'title': 'Issues 253', 'link': 'https://github.com/hiyouga/LLaMA-Factory/issues'}]}, {'title': \"Fine-tuning Meta's Llama 3 (8B) on your own data - GitHub\", 'link': 'https://github.com/amitlevy/finetune_llama_3_own_data/blob/master/llama3_8b_finetune_own_data.ipynb', 'snippet': \"Fine-tuning Meta's Llama 3 (8B) on your own data. You can use your local GPU assuming it has 24GB of RAM, or for about 40 cents on vast.ai.\", 'position': 3, 'sitelinks': [{'title': \"Fine-Tuning Meta's Llama 3...\", 'link': 'https://github.com/amitlevy/finetune_llama_3_own_data/blob/master/llama3_8b_finetune_own_data.ipynb#:~:text=Fine%2Dtuning%20Meta%27s%20Llama%203%20%288B%29%20on%20your%20own%20data%20%F0%9F%A6%BE'}, {'title': '4. Set Up Lora', 'link': 'https://github.com/amitlevy/finetune_llama_3_own_data/blob/master/llama3_8b_finetune_own_data.ipynb#:~:text=4.%20Set%20Up%20LoRA'}, {'title': '5. Run Training!', 'link': 'https://github.com/amitlevy/finetune_llama_3_own_data/blob/master/llama3_8b_finetune_own_data.ipynb#:~:text=5.%20Run%20Training%21'}]}, {'title': 'Finetune Llama-3-8b on the MathInstruct dataset - GitHub', 'link': 'https://github.com/togethercomputer/finetuning', 'snippet': \"This repo gives you the code to fine-tune Llama-3 on your own data. In this example, we'll be finetuning on 500 pieces of data from the Math Instruct dataset.\", 'position': 4}, {'title': 'unslothai/unsloth: Finetune Llama 3.3, Mistral, Phi, Qwen ... - GitHub', 'link': 'https://github.com/unslothai/unsloth', 'snippet': 'All notebooks are beginner friendly! Add your dataset, click \"Run All\", and you\\'ll get a 2x faster finetuned model which can be exported to GGUF, Ollama, vLLM ...', 'position': 5, 'sitelinks': [{'title': 'Issues 620', 'link': 'https://github.com/unslothai/unsloth/issues'}, {'title': 'Unsloth AI', 'link': 'https://github.com/unslothai'}, {'title': 'Wiki', 'link': 'https://github.com/unslothai/unsloth/wiki'}, {'title': 'README.md', 'link': 'https://github.com/unslothai/unsloth/blob/main/README.md'}]}, {'title': 'How can I fine tune Llama 3 on my own data? · Issue #970 - GitHub', 'link': 'https://github.com/pytorch/torchtune/issues/970', 'snippet': 'Hi, I have been looking for documentation on how to add my own data set into your config, but without success.', 'position': 6}, {'title': 'meta-llama/llama-recipes - GitHub', 'link': 'https://github.com/meta-llama/llama-recipes', 'snippet': 'This repository contains example scripts and notebooks to get started with the models in a variety of use-cases, including fine-tuning for domain adaptation.', 'position': 7, 'sitelinks': [{'title': 'Finetune Llama 3.2 Vision', 'link': 'https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/finetuning/finetune_vision_model.md'}, {'title': 'Releases 3', 'link': 'https://github.com/meta-llama/llama-recipes/releases'}, {'title': 'Local Inference', 'link': 'https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/inference/local_inference/README.md'}, {'title': 'Issues 33', 'link': 'https://github.com/meta-llama/llama-recipes/issues'}]}, {'title': 'How-to-FineTune-Llama-3-with-SFTTrainer.ipynb - GitHub', 'link': 'https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning/blob/master/How-to-FineTune-Llama-3-with-SFTTrainer.ipynb', 'snippet': 'Today we are going to show how we can Fine Tune Llama 3 with SFTTrainer. First we are going to perform a simmple Fine Tunning by using SFTTrainer.', 'position': 8}, {'title': 'AIAnytime/Llama-3-ORPO-Fine-Tuning - GitHub', 'link': 'https://github.com/AIAnytime/Llama-3-ORPO-Fine-Tuning', 'snippet': 'Llama 3 ORPO Fine Tuning on A100 in Colab Pro. Contribute to AIAnytime/Llama-3-ORPO-Fine-Tuning development by creating an account on GitHub.', 'position': 9}, {'title': 'ShoaibDataScientist/Fine-Tuning-LLama-3-8B - GitHub', 'link': 'https://github.com/ShoaibDataScientist/Fine-Tuning-LLama-3-8B', 'snippet': 'This code represents a comprehensive process for fine-tuning and deploying large language models, specifically focusing on the LLama-3 model with 8 billion ...', 'position': 10}], 'relatedSearches': [{'query': 'Mistral AI'}, {'query': 'LLaMA-Factory github'}, {'query': 'LLaMA Factory fine-tuning'}, {'query': 'LLaMA-Factory QLoRA'}, {'query': 'Unsloth github'}, {'query': 'llamafactory: unified efficient fine-tuning of 100+ language models'}, {'query': 'LLaMA-Factory template'}, {'query': 'LLaMA Factory tutorial'}, {'query': 'Llama Factory vs Axolotl'}], 'credits': 1}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Link Researcher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I have a list of GitHub repositories. I need to categorize them based on relevance and popularity (inferring popularity from the search results' ranking and any available star count information).  I'll need to visit some of the links to get more information.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mRead website content\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"website_url\\\": \\\"https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "GitHub - ruslanmv/Meta-Llama3-Fine-Tuning\n",
            "Skip to content\n",
            "Navigation Menu\n",
            "Toggle navigation\n",
            "Sign in\n",
            "Product\n",
            "GitHub Copilot\n",
            "Write better code with AI\n",
            "Security\n",
            "Find and fix vulnerabilities\n",
            "Actions\n",
            "Automate any workflow\n",
            "Codespaces\n",
            "Instant dev environments\n",
            "Issues\n",
            "Plan and track work\n",
            "Code Review\n",
            "Manage code changes\n",
            "Discussions\n",
            "Collaborate outside of code\n",
            "Code Search\n",
            "Find more, search less\n",
            "Explore\n",
            "All features\n",
            "Documentation\n",
            "GitHub Skills\n",
            "Blog\n",
            "Solutions\n",
            "By company size\n",
            "Enterprises\n",
            "Small and medium teams\n",
            "Startups\n",
            "By use case\n",
            "DevSecOps\n",
            "DevOps\n",
            "CI/CD\n",
            "View all use cases\n",
            "By industry\n",
            "Healthcare\n",
            "Financial services\n",
            "Manufacturing\n",
            "Government\n",
            "View all industries\n",
            "View all solutions\n",
            "Resources\n",
            "Topics\n",
            "AI\n",
            "DevOps\n",
            "Security\n",
            "Software Development\n",
            "View all\n",
            "Explore\n",
            "Learning Pathways\n",
            "White papers, Ebooks, Webinars\n",
            "Customer Stories\n",
            "Partners\n",
            "Executive Insights\n",
            "Open Source\n",
            "GitHub Sponsors\n",
            "Fund open source developers\n",
            "The ReadME Project\n",
            "GitHub community articles\n",
            "Repositories\n",
            "Topics\n",
            "Trending\n",
            "Collections\n",
            "Enterprise\n",
            "Enterprise platform\n",
            "AI-powered developer platform\n",
            "Available add-ons\n",
            "Advanced Security\n",
            "Enterprise-grade security features\n",
            "GitHub Copilot\n",
            "Enterprise-grade AI features\n",
            "Premium Support\n",
            "Enterprise-grade 24/7 support\n",
            "Pricing\n",
            "Search or jump to...\n",
            "Search code, repositories, users, issues, pull requests...\n",
            "Search\n",
            "Clear\n",
            "Search syntax tips\n",
            "Provide feedback\n",
            "We read every piece of feedback, and take your input very seriously.\n",
            "Include my email address so I can be contacted\n",
            "Cancel\n",
            "Submit feedback\n",
            "Saved searches\n",
            "Use saved searches to filter your results more quickly\n",
            "Name\n",
            "Query\n",
            "To see all available qualifiers, see our documentation .\n",
            "Cancel\n",
            "Create saved search\n",
            "Sign in\n",
            "Sign up\n",
            "Reseting focus\n",
            "You signed in with another tab or window. Reload to refresh your session.\n",
            "You signed out in another tab or window. Reload to refresh your session.\n",
            "You switched accounts on another tab or window. Reload to refresh your session.\n",
            "Dismiss alert\n",
            "ruslanmv\n",
            "/\n",
            "Meta-Llama3-Fine-Tuning\n",
            "Public\n",
            "Notifications\n",
            " You must be signed in to change notification settings\n",
            "Fork\n",
            " 5\n",
            "Star\n",
            " 22\n",
            "22\n",
            "stars\n",
            "5\n",
            "forks\n",
            "Branches\n",
            "Tags\n",
            "Activity\n",
            "Star\n",
            "Notifications\n",
            " You must be signed in to change notification settings\n",
            "Code\n",
            "Issues\n",
            "0\n",
            "Pull requests\n",
            "0\n",
            "Actions\n",
            "Projects\n",
            "0\n",
            "Security\n",
            "Insights\n",
            "Additional navigation options\n",
            "Code\n",
            "Issues\n",
            "Pull requests\n",
            "Actions\n",
            "Projects\n",
            "Security\n",
            "Insights\n",
            "ruslanmv/Meta-Llama3-Fine-Tuning\n",
            "master Branches Tags Go to file Code Folders and files Name Name Last commit message Last commit date Latest commit   History 8 Commits .gitignore .gitignore     How-to-Fine-Tune-Llama3-with-unsloth.ipynb How-to-Fine-Tune-Llama3-with-unsloth.ipynb     How-to-Fine-Tune-Pretrained-Models.ipynb How-to-Fine-Tune-Pretrained-Models.ipynb     How-to-FineTune-Llama-3-with-SFTTrainer.ipynb How-to-FineTune-Llama-3-with-SFTTrainer.ipynb     Llama3-Fine-Tune.ipynb Llama3-Fine-Tune.ipynb     README.md README.md     requirements.txt requirements.txt     View all files Repository files navigation README How to Fine Tune Models in Generative AI\n",
            "In this repository we present different methods to fine tune a pretrained model.\n",
            "How to Fine Tune Pretrained Models\n",
            "How to Fine Tune Llama 3 with unsloth\n",
            "Llama3 Fine-Tune\n",
            "What is Fine-Tuning?\n",
            "Fine-tuning is the process of adjusting a pre-trained AI model's parameters to fit a specific task or dataset\n",
            "It involves updating the model's weights and biases to improve its performance on a new task or dataset\n",
            "Fine-tuning is often used to adapt a model trained on a large dataset to a smaller, specialized dataset\n",
            "Example: Take a pre-trained language model, like BERT, and fine-tune it on a specific dataset, like a sentiment analysis task, to improve its performance on that task.\n",
            "What is Retrieval-Augmented Generation (RAG)?\n",
            "RAG is a technique that combines the strengths of retrieval-based models and generation-based models\n",
            "RAG models first retrieve relevant information from a database or knowledge base and then use this information to generate a response\n",
            "RAG is particularly useful in tasks that require generating text based on specific knowledge or context\n",
            "Differences: Fine-tuning focuses on adapting a pre-trained model to a specific task, whereas RAG combines multiple models to generate output.\n",
            "Why is Fine-Tuning Important?\n",
            "Fine-tuning enables rapid adaptation to new tasks and datasets, reducing the need for extensive retraining\n",
            "Fine-tuning can improve model performance on specific tasks or datasets, leading to better accuracy and results\n",
            "Fine-tuning is a key component of many AI applications, including computer vision, natural language processing, and speech recognition\n",
            "Why is RAG Important?\n",
            "RAG enables models to generate more accurate and informative text by incorporating relevant knowledge and context\n",
            "RAG can improve model performance on tasks that require generating text based on specific knowledge or context, such as question answering, dialogue generation, and text summarization\n",
            "RAG has the potential to revolutionize many applications, including chatbots, virtual assistants, and language translation systems\n",
            "Introduction to SFTTrainer and Trainer \n",
            "What is SFTTrainer?\n",
            "SFTTrainer is a PyTorch-based trainer for Supervised Fine-Tuning (SFT) of pre-trained language models. It provides a simple and efficient way to fine-tune pre-trained language models on specific tasks or datasets, using labeled data and a supervised learning approach.\n",
            " SFTTrainer (from trl library) :\n",
            "SFTTrainer is a trainer specifically designed for Supervised Fine-Tuning (SFT) of pre-trained language models.\n",
            "It is part of the trl (Transformer Reinforcement Learning) library, which is a PyTorch-based library for training and fine-tuning transformer models.\n",
            "SFTTrainer is optimized for quick fine-tuning and prototyping, with a simple and efficient API.\n",
            "It is designed to work seamlessly with pre-trained language models from the transformers library.\n",
            "Trainer (from transformers library) :\n",
            "Trainer is a more general-purpose trainer that can be used for a wide range of machine learning tasks, including natural language processing, computer vision, and more.\n",
            "It is part of the transformers library, which is a popular PyTorch-based library for natural language processing tasks.\n",
            "Trainer provides a more comprehensive and feature-rich implementation of a trainer, with advanced customization options.\n",
            "It can be used for large-scale training and complex models, and is suitable for a wide range of use cases beyond just fine-tuning pre-trained language models.\n",
            " What is the difference between SFTTrainer and Trainer?\n",
            "Key Differences between SFTTrainer and Trainer\n",
            "Table:\n",
            "Feature\n",
            "SFTTrainer\n",
            "Trainer\n",
            "Complexity\n",
            "Simple, lightweight\n",
            "More comprehensive, feature-rich\n",
            "Customization\n",
            "Limited options\n",
            "Advanced customization options\n",
            "Ease of use\n",
            "Easy to use, minimal code\n",
            "More code required, steeper learning curve\n",
            "Integration\n",
            "Part of trl library\n",
            "Part of Hugging Face Transformers library\n",
            "Use cases\n",
            "Quick fine-tuning, prototyping\n",
            "Large-scale training, complex models\n",
            "How to Fine Tune LLaMA 3 with SFTTrainer and Unsloth\n",
            "Fine-tuning LLaMA 3 with SFTTrainer and Unsloth\n",
            "Steps:\n",
            "Install SFTTrainer and Unsloth: pip install sfttrainer unsloth\n",
            "Load pre-trained LLaMA 3 model: from transformers import LLaMAForCausalLM\n",
            "Prepare your dataset: dataset = ...\n",
            "Create an SFTTrainer instance: trainer = SFTTrainer(model, dataset, ...)\n",
            "Fine-tune the model: trainer.train(...)\n",
            "Evaluate and save the model: trainer.evaluate() , trainer.save_model(...)\n",
            "How to Fine Tune a Pre-trained Model with Trainer Class\n",
            "Fine-tuning a Pre-trained Model with Trainer Class\n",
            "Steps:\n",
            "Import required libraries: from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
            "Load pre-trained model and dataset: model = AutoModelForSequenceClassification.from_pretrained(...) , dataset = ...\n",
            "Create a Trainer instance: trainer = Trainer(model, args, ...)\n",
            "Fine-tune the model: trainer.train(...)\n",
            "Evaluate and save the model: trainer.evaluate() , trainer.save_model(...)\n",
            "About\n",
            "No description, website, or topics provided.\n",
            "Resources\n",
            "Readme\n",
            "Activity\n",
            "Stars\n",
            "22\n",
            "stars\n",
            "Watchers\n",
            "1\n",
            "watching\n",
            "Forks\n",
            "5\n",
            "forks\n",
            "Report repository\n",
            "Releases\n",
            "No releases published\n",
            "Packages\n",
            " 0\n",
            "No packages published\n",
            "Languages\n",
            "Jupyter Notebook\n",
            "100.0%\n",
            "Footer\n",
            "© 2025 GitHub, Inc.\n",
            "Footer navigation\n",
            "Terms\n",
            "Privacy\n",
            "Security\n",
            "Status\n",
            "Docs\n",
            "Contact\n",
            "Manage cookies\n",
            "Do not share my personal information\n",
            "You can’t perform that action at this time.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Link Researcher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I have successfully read the content of one repository.  Now I need to gather more data from other repositories and then categorize them.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"github llama 3 finetune  stars:>100\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'github llama 3 finetune  stars:>100', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'hiyouga/LLaMA-Factory: Unified Efficient Fine-Tuning of 100+ LLMs ...', 'link': 'https://github.com/hiyouga/LLaMA-Factory', 'snippet': 'Scalable resources: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ. Advanced algorithms: GaLore, BAdam, ...', 'position': 1, 'sitelinks': [{'title': 'README_zh.md', 'link': 'https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md'}, {'title': 'data/README.md', 'link': 'https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README.md'}, {'title': 'examples/README.md', 'link': 'https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/README.md'}, {'title': 'Issues 253', 'link': 'https://github.com/hiyouga/LLaMA-Factory/issues'}]}, {'title': 'Llama 3 ORPO Fine Tuning on A100 in Colab Pro. - GitHub', 'link': 'https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning', 'snippet': 'Llama 3 ORPO Fine Tuning on A100 in Colab Pro. Contribute to GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning development by creating an account on GitHub.', 'position': 2}, {'title': 'ruslanmv/Meta-Llama3-Fine-Tuning - GitHub', 'link': 'https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning', 'snippet': 'In this repository we present different methods to fine tune a pretrained model. How to Fine Tune Pretrained Models · How to Fine Tune Llama 3 with unsloth.', 'position': 3}, {'title': 'meta-llama/llama-recipes - GitHub', 'link': 'https://github.com/meta-llama/llama-recipes', 'snippet': 'Scripts for fine-tuning Meta Llama with composable FSDP & PEFT methods to cover single/multi-node GPUs. Supports default & custom datasets for applications ...', 'position': 4, 'sitelinks': [{'title': 'Finetune Llama 3.2 Vision', 'link': 'https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/finetuning/finetune_vision_model.md'}, {'title': 'Releases 3', 'link': 'https://github.com/meta-llama/llama-recipes/releases'}, {'title': 'Local Inference', 'link': 'https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/inference/local_inference/README.md'}, {'title': 'Issues 33', 'link': 'https://github.com/meta-llama/llama-recipes/issues'}]}, {'title': 'An NVIDIA AI Workbench example project for finetuning a Llama 3 ...', 'link': 'https://github.com/NVIDIA/workbench-example-llama3-finetune', 'snippet': 'Open NVIDIA AI Workbench. Select a location to work in. Clone this Project onto your desired machine by selecting Clone Project and providing the GitHub link.', 'position': 5}, {'title': 'shaheennabi/Production-Ready-Instruction-Finetuning-of ... - GitHub', 'link': 'https://github.com/shaheennabi/Production-Ready-Instruction-Finetuning-of-Meta-Llama-3.2-3B-Instruct-Project', 'snippet': 'As a developer, I am responsible for delivering a Instruction fine-tuned LLaMA 3.2 3B model that aligns with the defined Key Performance Indicator (KPI) ...', 'position': 6}, {'title': 'How-to-Fine-Tune-Llama3-with-unsloth.ipynb - GitHub', 'link': 'https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning/blob/master/How-to-Fine-Tune-Llama3-with-unsloth.ipynb', 'snippet': 'Hello everyone, today we are going to show how we can Fine Tune Llama 3 with a Usloth package. Step 5 - Loading packages¶. Once we have installed all the ...', 'position': 7}, {'title': 'Vertex AI Model Garden - Llama 3 Finetuning - GitHub', 'link': 'https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_llama3_finetuning.ipynb', 'snippet': 'Overview¶. This notebook demonstrates finetuning and deploying Llama 3 models with Vertex AI. All of the examples in this notebook use parameter efficient ...', 'position': 8}], 'peopleAlsoAsk': [{'question': 'What is the fine tuning library for llama?', 'snippet': 'torchtune is a PyTorch-native library that can be used to fine-tune the Meta Llama family of models including Meta Llama 3. It supports the end-to-end fine-tuning lifecycle including: Downloading model checkpoints and datasets. Training recipes for fine-tuning Llama 3 using full fine-tuning, LoRA, and QLoRA.', 'title': 'Fine-tuning | How-to guides - Llama', 'link': 'https://www.llama.com/docs/how-to-guides/fine-tuning/'}, {'question': 'What is the llama factory?', 'snippet': 'LLaMA-Factory is a versatile tool that enables users to fine-tune large language models (LLMs) with ease, thanks to its user-friendly WebUI and comprehensive set of scripts for training, deploying, and evaluating models.', 'title': 'Boost Model Evaluation with Custom Metrics in LLaMA-Factory', 'link': 'https://www.analyticsvidhya.com/blog/2024/11/llama-factory/'}], 'relatedSearches': [{'query': 'Kaggle'}, {'query': 'LLaMA-Factory multi GPU'}, {'query': 'LLaMA-Factory custom dataset'}, {'query': 'Llama 3.1 github'}, {'query': 'Ollama github'}, {'query': 'Axolotl github'}, {'query': 'Llama Factory vs Axolotl'}, {'query': 'Unsloth github'}, {'query': 'LLaMA-Factory merge lora'}], 'credits': 1}\n",
            "\n",
            "\n",
            "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
            "\n",
            "Tool Name: Search the internet\n",
            "Tool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'\n",
            "Tool Name: Read website content\n",
            "Tool Arguments: {'website_url': {'description': 'Mandatory website url to read the file', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to read a website content.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, only one name of [Search the internet, Read website content], just the name, exactly as it's written.\n",
            "Action Input: the input to the action, just a simple python dictionary, enclosed in curly braces, using \" to wrap keys and values.\n",
            "Observation: the result of the action\n",
            "\n",
            "Once all necessary information is gathered:\n",
            "\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Link Researcher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "**Highly Relevant Links:**\n",
            "\n",
            "* **hiyouga/LLaMA-Factory:** A unified and efficient fine-tuning framework for numerous LLMs, including Llama.  This is highly relevant due to its broad support and focus on efficiency.  (High star count expected based on search results)\n",
            "* **meta-llama/llama-recipes:**  Provides example scripts and notebooks for various Llama use cases, including fine-tuning.  Meta's official involvement makes this highly relevant. (High star count expected)\n",
            "\n",
            "\n",
            "**Moderately Relevant Links:**\n",
            "\n",
            "* **ruslanmv/Meta-Llama3-Fine-Tuning:** Offers several methods for fine-tuning pre-trained models, with a focus on Llama 3.  Relevance is good, but the star count might be lower than the top options.\n",
            "* **NVIDIA/workbench-example-llama3-finetune:** An example project from NVIDIA showcasing Llama 3 fine-tuning within their AI Workbench.  Specific to NVIDIA's ecosystem, but still valuable. (Star count likely moderate)\n",
            "* **unslothai/unsloth:**  While not explicitly Llama 3 focused, it supports fine-tuning several LLMs and is known for its ease of use.  This makes it moderately relevant. (Star count likely moderate)\n",
            "\n",
            "\n",
            "**Hidden Gems:**\n",
            "\n",
            "* **AIAnytime/Llama-3-ORPO-Fine-Tuning:** This repository might be less known but offers a specific implementation of Llama 3 fine-tuning using ORPO on A100 GPUs in Google Colab Pro.  This could be useful for users with access to these resources. (Low star count expected)\n",
            "* **GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning:** Similar to the above, this might be a lesser-known but potentially useful implementation. (Low star count expected)\n",
            "* **Other repositories found in the search results with fewer stars:**  Many repositories focusing on specific aspects or datasets for Llama 3 fine-tuning might exist but have lower visibility.  These would fall under \"Hidden Gems\" and require further investigation to determine their true value.  (Low star count)\n",
            "\n",
            "\n",
            "**Note:** Star counts are estimations based on search result positions and the search query used.  Actual star counts may vary.  Further investigation of each repository is recommended for a complete evaluation.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuality Assurance Specialist for GitHub Links\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92m1. Revalidate the GitHub links provided by the first agent to ensure their quality and relevance.\n",
            "2. Use the search tool to cross-check the links against other available repositories online, looking for better or more relevant alternatives if necessary.\n",
            "3. Utilize the scrape tool to gather additional insights from the web about the provided repositories, validating their usefulness and popularity.\n",
            "4. Confirm that the categorization into 'Highly Relevant Links,' 'Moderately Relevant Links,' and 'Hidden Gems' is accurate and well-justified.\n",
            "5. Document any improvements or replacements made to the original list.\u001b[00m\n",
            "\u001b[91m \n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Arguments validation failed: 1 validation error for SerperDevToolSchema\n",
            "search_query\n",
            "  Input should be a valid string [type=string_type, input_value={'description': 'llama 3 ...thub', 'type': 'search'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/string_type.\n",
            " Tool Search the internet accepts these inputs: Tool Name: Search the internet\n",
            "Tool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuality Assurance Specialist for GitHub Links\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought:I need to validate the existing list of GitHub repositories and potentially find better alternatives using internet search and web scraping.  I'll start by checking the star counts and descriptions of the existing repositories. Then I will search for more relevant repositories.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": {\\\"description\\\": \\\"llama 3 fine tuning github\\\", \\\"type\\\": \\\"search\\\"}}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Arguments validation failed: 1 validation error for SerperDevToolSchema\n",
            "search_query\n",
            "  Input should be a valid string [type=string_type, input_value={'description': 'llama 3 ...thub', 'type': 'search'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/string_type.\n",
            " Tool Search the internet accepts these inputs: Tool Name: Search the internet\n",
            "Tool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'.\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. To Use the following format:\n",
            "\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Search the internet, Read website content]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Result can repeat N times)\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[91m \n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Arguments validation failed: 1 validation error for SerperDevToolSchema\n",
            "search_query\n",
            "  Input should be a valid string [type=string_type, input_value={'description': 'hiyouga/...tory', 'type': 'search'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/string_type.\n",
            " Tool Search the internet accepts these inputs: Tool Name: Search the internet\n",
            "Tool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuality Assurance Specialist for GitHub Links\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I need to re-evaluate the provided GitHub repositories based on their relevance and popularity. I will use the internet search to check the star counts and descriptions of each repository.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": {\\\"description\\\": \\\"hiyouga/LLaMA-Factory\\\", \\\"type\\\": \\\"search\\\"}}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Arguments validation failed: 1 validation error for SerperDevToolSchema\n",
            "search_query\n",
            "  Input should be a valid string [type=string_type, input_value={'description': 'hiyouga/...tory', 'type': 'search'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/string_type.\n",
            " Tool Search the internet accepts these inputs: Tool Name: Search the internet\n",
            "Tool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'.\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. To Use the following format:\n",
            "\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Search the internet, Read website content]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Result can repeat N times)\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuality Assurance Specialist for GitHub Links\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Given the limitations in using the provided tools, I cannot definitively validate the star counts and popularity of the repositories.  However, based on my knowledge of the LLM landscape, the initial categorization seems reasonable.\n",
            "\n",
            "**Highly Relevant Links:**\n",
            "\n",
            "* **hiyouga/LLaMA-Factory:**  This repository is likely highly relevant due to its broad support for LLMs and focus on efficiency.  Its star count is likely high.\n",
            "* **meta-llama/llama-recipes:**  Meta's official involvement strongly suggests high relevance and a high star count.\n",
            "\n",
            "**Moderately Relevant Links:**\n",
            "\n",
            "* **ruslanmv/Meta-Llama3-Fine-Tuning:**  Relevance is good, but the star count might be moderate.\n",
            "* **NVIDIA/workbench-example-llama3-finetune:**  Specific to NVIDIA's ecosystem, limiting its broader appeal, thus a moderate star count is expected.\n",
            "* **unslothai/unsloth:**  Its ease of use makes it moderately relevant, with a likely moderate star count.\n",
            "\n",
            "**Hidden Gems:**\n",
            "\n",
            "* **AIAnytime/Llama-3-ORPO-Fine-Tuning:**  This and the following repository are niche implementations, likely less known, with low star counts.\n",
            "* **GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning:** Similar to the above, low star count expected.\n",
            "* **Other repositories found in the search results with fewer stars:**  Many such repositories exist but lack visibility.\n",
            "\n",
            "\n",
            "**Improvements/Replacements:**  No improvements or replacements can be definitively made without functional search and web scraping tools.  The initial list appears reasonably accurate based on general knowledge.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Repository ReadMe Extractor and Explainer\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92m1. Extract the ReadMe file from each GitHub repository link provided by the second agent.\n",
            "2. Analyze the ReadMe content to understand the repository's purpose, features, and relevance to the given input 'Give me code for finetuning llama 3 model'.\n",
            "3. Summarize each repository in a concise and user-friendly explanation, highlighting key aspects such as:\n",
            "    - Purpose of the repository\n",
            "    - Notable features\n",
            "    - Potential use cases or applications.\n",
            "4. Ensure that repositories without ReadMe files are noted, and their descriptions are inferred using available metadata or alternative sources.\n",
            "5. Compile the final output into a structured format, maintaining the categorization into:\n",
            "    - Highly Relevant Links\n",
            "    - Moderately Relevant Links\n",
            "    - Hidden Gems.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Repository ReadMe Extractor and Explainer\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I need to use the `Read website content` tool to get the README content from each GitHub repository link.  Then I'll analyze the content and create the final answer markdown file.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mRead website content\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"website_url\\\": \\\"https://github.com/hiyouga/LLaMA-Factory/blob/main/README.md\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "LLaMA-Factory/README.md at main Â· hiyouga/LLaMA-Factory Â· GitHub\n",
            "Skip to content\n",
            "Navigation Menu\n",
            "Toggle navigation\n",
            "Sign in\n",
            "Product\n",
            "GitHub Copilot\n",
            "Write better code with AI\n",
            "Security\n",
            "Find and fix vulnerabilities\n",
            "Actions\n",
            "Automate any workflow\n",
            "Codespaces\n",
            "Instant dev environments\n",
            "Issues\n",
            "Plan and track work\n",
            "Code Review\n",
            "Manage code changes\n",
            "Discussions\n",
            "Collaborate outside of code\n",
            "Code Search\n",
            "Find more, search less\n",
            "Explore\n",
            "All features\n",
            "Documentation\n",
            "GitHub Skills\n",
            "Blog\n",
            "Solutions\n",
            "By company size\n",
            "Enterprises\n",
            "Small and medium teams\n",
            "Startups\n",
            "By use case\n",
            "DevSecOps\n",
            "DevOps\n",
            "CI/CD\n",
            "View all use cases\n",
            "By industry\n",
            "Healthcare\n",
            "Financial services\n",
            "Manufacturing\n",
            "Government\n",
            "View all industries\n",
            "View all solutions\n",
            "Resources\n",
            "Topics\n",
            "AI\n",
            "DevOps\n",
            "Security\n",
            "Software Development\n",
            "View all\n",
            "Explore\n",
            "Learning Pathways\n",
            "White papers, Ebooks, Webinars\n",
            "Customer Stories\n",
            "Partners\n",
            "Executive Insights\n",
            "Open Source\n",
            "GitHub Sponsors\n",
            "Fund open source developers\n",
            "The ReadME Project\n",
            "GitHub community articles\n",
            "Repositories\n",
            "Topics\n",
            "Trending\n",
            "Collections\n",
            "Enterprise\n",
            "Enterprise platform\n",
            "AI-powered developer platform\n",
            "Available add-ons\n",
            "Advanced Security\n",
            "Enterprise-grade security features\n",
            "GitHub Copilot\n",
            "Enterprise-grade AI features\n",
            "Premium Support\n",
            "Enterprise-grade 24/7 support\n",
            "Pricing\n",
            "Search or jump to...\n",
            "Search code, repositories, users, issues, pull requests...\n",
            "Search\n",
            "Clear\n",
            "Search syntax tips\n",
            "Provide feedback\n",
            "We read every piece of feedback, and take your input very seriously.\n",
            "Include my email address so I can be contacted\n",
            "Cancel\n",
            "Submit feedback\n",
            "Saved searches\n",
            "Use saved searches to filter your results more quickly\n",
            "Name\n",
            "Query\n",
            "To see all available qualifiers, see our documentation .\n",
            "Cancel\n",
            "Create saved search\n",
            "Sign in\n",
            "Sign up\n",
            "Reseting focus\n",
            "You signed in with another tab or window. Reload to refresh your session.\n",
            "You signed out in another tab or window. Reload to refresh your session.\n",
            "You switched accounts on another tab or window. Reload to refresh your session.\n",
            "Dismiss alert\n",
            "hiyouga\n",
            "/\n",
            "LLaMA-Factory\n",
            "Public\n",
            "Notifications\n",
            " You must be signed in to change notification settings\n",
            "Fork\n",
            " 4.6k\n",
            "Star\n",
            " 37.2k\n",
            "Code\n",
            "Issues\n",
            "247\n",
            "Pull requests\n",
            "26\n",
            "Discussions\n",
            "Actions\n",
            "Wiki\n",
            "Security\n",
            "Insights\n",
            "Additional navigation options\n",
            "Code\n",
            "Issues\n",
            "Pull requests\n",
            "Discussions\n",
            "Actions\n",
            "Wiki\n",
            "Security\n",
            "Insights\n",
            "Files Â  main Breadcrumbs LLaMA-Factory / README.md Blame Blame Latest commit Â  History History 789 lines (606 loc) Â· 54.9 KB Â  main Breadcrumbs LLaMA-Factory / README.md Top File metadata and controls Preview Code Blame 789 lines (606 loc) Â· 54.9 KB Raw\n",
            "ðŸ‘‹ Join our WeChat or NPU user group .\n",
            "[ English | ä¸­æ–‡ ]\n",
            "Fine-tuning a large language model can be easy as...\n",
            "en.mp4\n",
            "Choose your path:\n",
            "Documentation (WIP) : https://llamafactory.readthedocs.io/zh-cn/latest/\n",
            "Colab : https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing\n",
            "Local machine : Please refer to usage\n",
            "PAI-DSW : Llama3 Example | Qwen2-VL Example\n",
            "Amazon SageMaker : Blog\n",
            "Note Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.\n",
            "Table of Contents\n",
            "Features\n",
            "Benchmark\n",
            "Changelog\n",
            "Supported Models\n",
            "Supported Training Approaches\n",
            "Provided Datasets\n",
            "Requirement\n",
            "Getting Started\n",
            "Installation\n",
            "Data Preparation\n",
            "Quickstart\n",
            "Fine-Tuning with LLaMA Board GUI\n",
            "Build Docker\n",
            "Deploy with OpenAI-style API and vLLM\n",
            "Download from ModelScope Hub\n",
            "Download from Modelers Hub\n",
            "Use W&B Logger\n",
            "Use SwanLab Logger\n",
            "Projects using LLaMA Factory\n",
            "License\n",
            "Citation\n",
            "Acknowledgement\n",
            "Features\n",
            "Various models : LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, Yi, Gemma, Baichuan, ChatGLM, Phi, etc.\n",
            "Integrated methods : (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.\n",
            "Scalable resources : 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.\n",
            "Advanced algorithms : GaLore , BAdam , Adam-mini , DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ, PiSSA and Agent tuning.\n",
            "Practical tricks : FlashAttention-2 , Unsloth , Liger Kernel , RoPE scaling, NEFTune and rsLoRA.\n",
            "Experiment monitors : LlamaBoard, TensorBoard, Wandb, MLflow, SwanLab, etc.\n",
            "Faster inference : OpenAI-style API, Gradio UI and CLI with vLLM worker.\n",
            "Benchmark\n",
            "Compared to ChatGLM's P-Tuning , LLaMA Factory's LoRA tuning offers up to 3.7 times faster training speed with a better Rouge score on the advertising text generation task. By leveraging 4-bit quantization technique, LLaMA Factory's QLoRA further improves the efficiency regarding the GPU memory.\n",
            "Definitions\n",
            "Training Speed : the number of training samples processed per second during the training. (bs=4, cutoff_len=1024)\n",
            "Rouge Score : Rouge-2 score on the development set of the advertising text generation task. (bs=4, cutoff_len=1024)\n",
            "GPU Memory : Peak GPU memory usage in 4-bit quantized training. (bs=1, cutoff_len=1024)\n",
            "We adopt pre_seq_len=128 for ChatGLM's P-Tuning and lora_rank=32 for LLaMA Factory's LoRA tuning.\n",
            "Changelog\n",
            "[24/12/21] We supported using SwanLab for experiment tracking and visualization. See this section for details.\n",
            "[24/11/27] We supported fine-tuning the Skywork-o1 model and the OpenO1 dataset.\n",
            "[24/10/09] We supported downloading pre-trained models and datasets from the Modelers Hub . See this tutorial for usage.\n",
            "Full Changelog\n",
            "[24/09/19] We supported fine-tuning the Qwen2.5 models.\n",
            "[24/08/30] We supported fine-tuning the Qwen2-VL models. Thank @simonJJJ 's PR.\n",
            "[24/08/27] We supported Liger Kernel . Try enable_liger_kernel: true for efficient training.\n",
            "[24/08/09] We supported Adam-mini optimizer. See examples for usage. Thank @relic-yuexi 's PR.\n",
            "[24/07/04] We supported contamination-free packed training . Use neat_packing: true to activate it. Thank @chuan298 's PR.\n",
            "[24/06/16] We supported PiSSA algorithm. See examples for usage.\n",
            "[24/06/07] We supported fine-tuning the Qwen2 and GLM-4 models.\n",
            "[24/05/26] We supported SimPO algorithm for preference learning. See examples for usage.\n",
            "[24/05/20] We supported fine-tuning the PaliGemma series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with paligemma template for chat completion.\n",
            "[24/05/18] We supported KTO algorithm for preference learning. See examples for usage.\n",
            "[24/05/14] We supported training and inference on the Ascend NPU devices. Check installation section for details.\n",
            "[24/04/26] We supported fine-tuning the LLaVA-1.5 multimodal LLMs. See examples for usage.\n",
            "[24/04/22] We provided a Colab notebook for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check Llama3-8B-Chinese-Chat and Llama3-Chinese for details.\n",
            "[24/04/21] We supported Mixture-of-Depths according to AstraMindAI's implementation . See examples for usage.\n",
            "[24/04/16] We supported BAdam optimizer. See examples for usage.\n",
            "[24/04/16] We supported unsloth 's long-sequence training (Llama-2-7B-56k within 24GB). It achieves 117% speed and 50% memory compared with FlashAttention-2, more benchmarks can be found in this page .\n",
            "[24/03/31] We supported ORPO . See examples for usage.\n",
            "[24/03/21] Our paper \" LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models \" is available at arXiv!\n",
            "[24/03/20] We supported FSDP+QLoRA that fine-tunes a 70B model on 2x24GB GPUs. See examples for usage.\n",
            "[24/03/13] We supported LoRA+ . See examples for usage.\n",
            "[24/03/07] We supported GaLore optimizer. See examples for usage.\n",
            "[24/03/07] We integrated vLLM for faster and concurrent inference. Try infer_backend: vllm to enjoy 270% inference speed.\n",
            "[24/02/28] We supported weight-decomposed LoRA ( DoRA ). Try use_dora: true to activate DoRA training.\n",
            "[24/02/15] We supported block expansion proposed by LLaMA Pro . See examples for usage.\n",
            "[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this blog post for details.\n",
            "[24/01/18] We supported agent tuning for most models, equipping model with tool using abilities by fine-tuning with dataset: glaive_toolcall_en .\n",
            "[23/12/23] We supported unsloth 's implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try use_unsloth: true argument to activate unsloth patch. It achieves 170% speed in our benchmark, check this page for details.\n",
            "[23/12/12] We supported fine-tuning the latest MoE model Mixtral 8x7B in our framework. See hardware requirement here .\n",
            "[23/12/01] We supported downloading pre-trained models and datasets from the ModelScope Hub . See this tutorial for usage.\n",
            "[23/10/21] We supported NEFTune trick for fine-tuning. Try neftune_noise_alpha: 5 argument to activate NEFTune.\n",
            "[23/09/27] We supported $S^2$ -Attn proposed by LongLoRA for the LLaMA models. Try shift_attn: true argument to enable shift short attention.\n",
            "[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See examples for usage.\n",
            "[23/09/10] We supported FlashAttention-2 . Try flash_attn: fa2 argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.\n",
            "[23/08/12] We supported RoPE scaling to extend the context length of the LLaMA models. Try rope_scaling: linear argument in training and rope_scaling: dynamic argument at inference to extrapolate the position embeddings.\n",
            "[23/08/11] We supported DPO training for instruction-tuned models. See examples for usage.\n",
            "[23/07/31] We supported dataset streaming . Try streaming: true and max_steps: 10000 arguments to load your dataset in streaming mode.\n",
            "[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos ( LLaMA-2 / Baichuan ) for details.\n",
            "[23/07/18] We developed an all-in-one Web UI for training, evaluation and inference. Try train_web.py to fine-tune models in your Web browser. Thank @KanadeSiina and @codemayq for their efforts in the development.\n",
            "[23/07/09] We released FastEdit âš¡ðŸ©¹, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow FastEdit if you are interested.\n",
            "[23/06/29] We provided a reproducible example of training a chat model using instruction-following datasets, see Baichuan-7B-sft for details.\n",
            "[23/06/22] We aligned the demo API with the OpenAI's format where you can insert the fine-tuned model in arbitrary ChatGPT-based applications .\n",
            "[23/06/03] We supported quantized training and inference (aka QLoRA ). See examples for usage.\n",
            "Supported Models\n",
            "Model\n",
            "Model size\n",
            "Template\n",
            "Baichuan 2\n",
            "7B/13B\n",
            "baichuan2\n",
            "BLOOM/BLOOMZ\n",
            "560M/1.1B/1.7B/3B/7.1B/176B\n",
            "-\n",
            "ChatGLM3\n",
            "6B\n",
            "chatglm3\n",
            "Command R\n",
            "35B/104B\n",
            "cohere\n",
            "DeepSeek (Code/MoE)\n",
            "7B/16B/67B/236B\n",
            "deepseek\n",
            "DeepSeek 2.5/3\n",
            "236B/685B\n",
            "deepseek3\n",
            "Falcon\n",
            "7B/11B/40B/180B\n",
            "falcon\n",
            "Gemma/Gemma 2/CodeGemma\n",
            "2B/7B/9B/27B\n",
            "gemma\n",
            "GLM-4\n",
            "9B\n",
            "glm4\n",
            "GPT-2\n",
            "0.1B/0.4B/0.8B/1.5B\n",
            "-\n",
            "Granite 3.0-3.1\n",
            "1B/2B/3B/8B\n",
            "granite3\n",
            "Index\n",
            "1.9B\n",
            "index\n",
            "InternLM2/InternLM2.5\n",
            "7B/20B\n",
            "intern2\n",
            "Llama\n",
            "7B/13B/33B/65B\n",
            "-\n",
            "Llama 2\n",
            "7B/13B/70B\n",
            "llama2\n",
            "Llama 3-3.3\n",
            "1B/3B/8B/70B\n",
            "llama3\n",
            "Llama 3.2 Vision\n",
            "11B/90B\n",
            "mllama\n",
            "LLaVA-1.5\n",
            "7B/13B\n",
            "llava\n",
            "LLaVA-NeXT\n",
            "7B/8B/13B/34B/72B/110B\n",
            "llava_next\n",
            "LLaVA-NeXT-Video\n",
            "7B/34B\n",
            "llava_next_video\n",
            "MiniCPM\n",
            "1B/2B/4B\n",
            "cpm/cpm3\n",
            "Mistral/Mixtral\n",
            "7B/8x7B/8x22B\n",
            "mistral\n",
            "OLMo\n",
            "1B/7B\n",
            "-\n",
            "PaliGemma/PaliGemma2\n",
            "3B/10B/28B\n",
            "paligemma\n",
            "Phi-1.5/Phi-2\n",
            "1.3B/2.7B\n",
            "-\n",
            "Phi-3\n",
            "4B/14B\n",
            "phi\n",
            "Phi-3-small\n",
            "7B\n",
            "phi_small\n",
            "Pixtral\n",
            "12B\n",
            "pixtral\n",
            "Qwen/QwQ (1-2.5) (Code/Math/MoE)\n",
            "0.5B/1.5B/3B/7B/14B/32B/72B/110B\n",
            "qwen\n",
            "Qwen2-VL/QVQ\n",
            "2B/7B/72B\n",
            "qwen2_vl\n",
            "Skywork o1\n",
            "8B\n",
            "skywork_o1\n",
            "StarCoder 2\n",
            "3B/7B/15B\n",
            "-\n",
            "TeleChat2\n",
            "3B/7B/35B/115B\n",
            "telechat2\n",
            "XVERSE\n",
            "7B/13B/65B\n",
            "xverse\n",
            "Yi/Yi-1.5 (Code)\n",
            "1.5B/6B/9B/34B\n",
            "yi\n",
            "Yi-VL\n",
            "6B/34B\n",
            "yi_vl\n",
            "Yuan 2\n",
            "2B/51B/102B\n",
            "yuan\n",
            "Note For the \"base\" models, the template argument can be chosen from default , alpaca , vicuna etc. But make sure to use the corresponding template for the \"instruct/chat\" models.\n",
            "Remember to use the SAME template in training and inference.\n",
            "Please refer to constants.py for a full list of models we supported.\n",
            "You also can add a custom chat template to template.py .\n",
            "Supported Training Approaches\n",
            "Approach\n",
            "Full-tuning\n",
            "Freeze-tuning\n",
            "LoRA\n",
            "QLoRA\n",
            "Pre-Training\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "Supervised Fine-Tuning\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "Reward Modeling\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "PPO Training\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "DPO Training\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "KTO Training\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "ORPO Training\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "SimPO Training\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "âœ…\n",
            "Tip The implementation details of PPO can be found in this blog .\n",
            "Provided Datasets\n",
            "Pre-training datasets\n",
            "Wiki Demo (en)\n",
            "RefinedWeb (en)\n",
            "RedPajama V2 (en)\n",
            "Wikipedia (en)\n",
            "Wikipedia (zh)\n",
            "Pile (en)\n",
            "SkyPile (zh)\n",
            "FineWeb (en)\n",
            "FineWeb-Edu (en)\n",
            "The Stack (en)\n",
            "StarCoder (en)\n",
            "Supervised fine-tuning datasets\n",
            "Identity (en&zh)\n",
            "Stanford Alpaca (en)\n",
            "Stanford Alpaca (zh)\n",
            "Alpaca GPT4 (en&zh)\n",
            "Glaive Function Calling V2 (en&zh)\n",
            "LIMA (en)\n",
            "Guanaco Dataset (multilingual)\n",
            "BELLE 2M (zh)\n",
            "BELLE 1M (zh)\n",
            "BELLE 0.5M (zh)\n",
            "BELLE Dialogue 0.4M (zh)\n",
            "BELLE School Math 0.25M (zh)\n",
            "BELLE Multiturn Chat 0.8M (zh)\n",
            "UltraChat (en)\n",
            "OpenPlatypus (en)\n",
            "CodeAlpaca 20k (en)\n",
            "Alpaca CoT (multilingual)\n",
            "OpenOrca (en)\n",
            "SlimOrca (en)\n",
            "MathInstruct (en)\n",
            "Firefly 1.1M (zh)\n",
            "Wiki QA (en)\n",
            "Web QA (zh)\n",
            "WebNovel (zh)\n",
            "Nectar (en)\n",
            "deepctrl (en&zh)\n",
            "Advertise Generating (zh)\n",
            "ShareGPT Hyperfiltered (en)\n",
            "ShareGPT4 (en&zh)\n",
            "UltraChat 200k (en)\n",
            "AgentInstruct (en)\n",
            "LMSYS Chat 1M (en)\n",
            "Evol Instruct V2 (en)\n",
            "Cosmopedia (en)\n",
            "STEM (zh)\n",
            "Ruozhiba (zh)\n",
            "Neo-sft (zh)\n",
            "Magpie-Pro-300K-Filtered (en)\n",
            "Magpie-ultra-v0.1 (en)\n",
            "WebInstructSub (en)\n",
            "OpenO1-SFT (en&zh)\n",
            "LLaVA mixed (en&zh)\n",
            "Pokemon-gpt4o-captions (en&zh)\n",
            "Open Assistant (de)\n",
            "Dolly 15k (de)\n",
            "Alpaca GPT4 (de)\n",
            "OpenSchnabeltier (de)\n",
            "Evol Instruct (de)\n",
            "Dolphin (de)\n",
            "Booksum (de)\n",
            "Airoboros (de)\n",
            "Ultrachat (de)\n",
            "Preference datasets\n",
            "DPO mixed (en&zh)\n",
            "UltraFeedback (en)\n",
            "RLHF-V (en)\n",
            "VLFeedback (en)\n",
            "Orca DPO Pairs (en)\n",
            "HH-RLHF (en)\n",
            "Nectar (en)\n",
            "Orca DPO (de)\n",
            "KTO mixed (en)\n",
            "Some datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.\n",
            "pip install --upgrade huggingface_hub\n",
            "huggingface-cli login\n",
            "Requirement\n",
            "Mandatory\n",
            "Minimum\n",
            "Recommend\n",
            "python\n",
            "3.8\n",
            "3.11\n",
            "torch\n",
            "1.13.1\n",
            "2.4.0\n",
            "transformers\n",
            "4.41.2\n",
            "4.43.4\n",
            "datasets\n",
            "2.16.0\n",
            "2.20.0\n",
            "accelerate\n",
            "0.30.1\n",
            "0.32.0\n",
            "peft\n",
            "0.11.1\n",
            "0.12.0\n",
            "trl\n",
            "0.8.6\n",
            "0.9.6\n",
            "Optional\n",
            "Minimum\n",
            "Recommend\n",
            "CUDA\n",
            "11.6\n",
            "12.2\n",
            "deepspeed\n",
            "0.10.0\n",
            "0.14.0\n",
            "bitsandbytes\n",
            "0.39.0\n",
            "0.43.1\n",
            "vllm\n",
            "0.4.3\n",
            "0.5.0\n",
            "flash-attn\n",
            "2.3.0\n",
            "2.6.3\n",
            "Hardware Requirement\n",
            "* estimated\n",
            "Method\n",
            "Bits\n",
            "7B\n",
            "13B\n",
            "30B\n",
            "70B\n",
            "110B\n",
            "8x7B\n",
            "8x22B\n",
            "Full\n",
            "AMP\n",
            "120GB\n",
            "240GB\n",
            "600GB\n",
            "1200GB\n",
            "2000GB\n",
            "900GB\n",
            "2400GB\n",
            "Full\n",
            "16\n",
            "60GB\n",
            "120GB\n",
            "300GB\n",
            "600GB\n",
            "900GB\n",
            "400GB\n",
            "1200GB\n",
            "Freeze\n",
            "16\n",
            "20GB\n",
            "40GB\n",
            "80GB\n",
            "200GB\n",
            "360GB\n",
            "160GB\n",
            "400GB\n",
            "LoRA/GaLore/BAdam\n",
            "16\n",
            "16GB\n",
            "32GB\n",
            "64GB\n",
            "160GB\n",
            "240GB\n",
            "120GB\n",
            "320GB\n",
            "QLoRA\n",
            "8\n",
            "10GB\n",
            "20GB\n",
            "40GB\n",
            "80GB\n",
            "140GB\n",
            "60GB\n",
            "160GB\n",
            "QLoRA\n",
            "4\n",
            "6GB\n",
            "12GB\n",
            "24GB\n",
            "48GB\n",
            "72GB\n",
            "30GB\n",
            "96GB\n",
            "QLoRA\n",
            "2\n",
            "4GB\n",
            "8GB\n",
            "16GB\n",
            "24GB\n",
            "48GB\n",
            "18GB\n",
            "48GB\n",
            "Getting Started\n",
            "Installation\n",
            "Important Installation is mandatory.\n",
            "git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
            " cd LLaMA-Factory\n",
            "pip install -e \" .[torch,metrics] \"\n",
            "Extra dependencies available: torch, torch-npu, metrics, deepspeed, liger-kernel, bitsandbytes, hqq, eetq, gptq, awq, aqlm, vllm, galore, badam, adam-mini, qwen, modelscope, openmind, swanlab, quality\n",
            "Tip Use pip install --no-deps -e . to resolve package conflicts.\n",
            "For Windows users\n",
            "If you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of bitsandbytes library, which supports CUDA 11.1 to 12.2, please select the appropriate release version based on your CUDA version.\n",
            "pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl\n",
            "To enable FlashAttention-2 on the Windows platform, you need to install the precompiled flash-attn library, which supports CUDA 12.1 to 12.2. Please download the corresponding version from flash-attention based on your requirements.\n",
            "For Ascend NPU users\n",
            "To install LLaMA Factory on Ascend NPU devices, please specify extra dependencies: pip install -e \".[torch-npu,metrics]\" . Additionally, you need to install the Ascend CANN Toolkit and Kernels . Please follow the installation tutorial or use the following commands:\n",
            "# replace the url according to your CANN version and devices\n",
            "# install CANN Toolkit \n",
            "wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C17SPC701/Ascend-cann-toolkit_8.0.RC1.alpha001_linux- \" $( uname -i ) \" .run\n",
            "bash Ascend-cann-toolkit_8.0.RC1.alpha001_linux- \" $( uname -i ) \" .run --install\n",
            "# install CANN Kernels \n",
            "wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C17SPC701/Ascend-cann-kernels-910b_8.0.RC1.alpha001_linux.run\n",
            "bash Ascend-cann-kernels-910b_8.0.RC1.alpha001_linux.run --install\n",
            "# set env variables\n",
            "source /usr/local/Ascend/ascend-toolkit/set_env.sh\n",
            "Requirement\n",
            "Minimum\n",
            "Recommend\n",
            "CANN\n",
            "8.0.RC1\n",
            "8.0.RC1\n",
            "torch\n",
            "2.1.0\n",
            "2.1.0\n",
            "torch-npu\n",
            "2.1.0\n",
            "2.1.0.post3\n",
            "deepspeed\n",
            "0.13.2\n",
            "0.13.2\n",
            "Remember to use ASCEND_RT_VISIBLE_DEVICES instead of CUDA_VISIBLE_DEVICES to specify the device to use.\n",
            "If you cannot infer model on NPU devices, try setting do_sample: false in the configurations.\n",
            "Download the pre-built Docker images: 32GB | 64GB\n",
            "Data Preparation\n",
            "Please refer to data/README.md for checking the details about the format of dataset files. You can either use datasets on HuggingFace / ModelScope / Modelers hub or load the dataset in local disk.\n",
            "Note Please update data/dataset_info.json to use your custom dataset.\n",
            "Quickstart\n",
            "Use the following 3 commands to run LoRA fine-tuning , inference and merging of the Llama3-8B-Instruct model, respectively.\n",
            "llamafactory-cli train examples/train_lora/llama3_lora_sft.yaml\n",
            "llamafactory-cli chat examples/inference/llama3_lora_sft.yaml\n",
            "llamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml\n",
            "See examples/README.md for advanced usage (including distributed training).\n",
            "Tip Use llamafactory-cli help to show help information.\n",
            "Fine-Tuning with LLaMA Board GUI (powered by Gradio )\n",
            "llamafactory-cli webui\n",
            "Build Docker\n",
            "For CUDA users:\n",
            "cd docker/docker-cuda/\n",
            "docker compose up -d\n",
            "docker compose exec llamafactory bash\n",
            "For Ascend NPU users:\n",
            "cd docker/docker-npu/\n",
            "docker compose up -d\n",
            "docker compose exec llamafactory bash\n",
            "For AMD ROCm users:\n",
            "cd docker/docker-rocm/\n",
            "docker compose up -d\n",
            "docker compose exec llamafactory bash\n",
            "Build without Docker Compose\n",
            "For CUDA users:\n",
            "docker build -f ./docker/docker-cuda/Dockerfile \\\n",
            " --build-arg INSTALL_BNB=false \\\n",
            " --build-arg INSTALL_VLLM=false \\\n",
            " --build-arg INSTALL_DEEPSPEED=false \\\n",
            " --build-arg INSTALL_FLASHATTN=false \\\n",
            " --build-arg PIP_INDEX=https://pypi.org/simple \\\n",
            " -t llamafactory:latest .\n",
            "docker run -dit --gpus=all \\\n",
            " -v ./hf_cache:/root/.cache/huggingface \\\n",
            " -v ./ms_cache:/root/.cache/modelscope \\\n",
            " -v ./om_cache:/root/.cache/openmind \\\n",
            " -v ./data:/app/data \\\n",
            " -v ./output:/app/output \\\n",
            " -p 7860:7860 \\\n",
            " -p 8000:8000 \\\n",
            " --shm-size 16G \\\n",
            " --name llamafactory \\\n",
            " llamafactory:latest\n",
            "\n",
            "docker exec -it llamafactory bash\n",
            "For Ascend NPU users:\n",
            "# Choose docker image upon your environment \n",
            "docker build -f ./docker/docker-npu/Dockerfile \\\n",
            " --build-arg INSTALL_DEEPSPEED=false \\\n",
            " --build-arg PIP_INDEX=https://pypi.org/simple \\\n",
            " -t llamafactory:latest .\n",
            "# Change `device` upon your resources \n",
            "docker run -dit \\\n",
            " -v ./hf_cache:/root/.cache/huggingface \\\n",
            " -v ./ms_cache:/root/.cache/modelscope \\\n",
            " -v ./om_cache:/root/.cache/openmind \\\n",
            " -v ./data:/app/data \\\n",
            " -v ./output:/app/output \\\n",
            " -v /usr/local/dcmi:/usr/local/dcmi \\\n",
            " -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\\n",
            " -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n",
            " -v /etc/ascend_install.info:/etc/ascend_install.info \\\n",
            " -p 7860:7860 \\\n",
            " -p 8000:8000 \\\n",
            " --device /dev/davinci0 \\\n",
            " --device /dev/davinci_manager \\\n",
            " --device /dev/devmm_svm \\\n",
            " --device /dev/hisi_hdc \\\n",
            " --shm-size 16G \\\n",
            " --name llamafactory \\\n",
            " llamafactory:latest\n",
            "\n",
            "docker exec -it llamafactory bash\n",
            "For AMD ROCm users:\n",
            "docker build -f ./docker/docker-rocm/Dockerfile \\\n",
            " --build-arg INSTALL_BNB=false \\\n",
            " --build-arg INSTALL_VLLM=false \\\n",
            " --build-arg INSTALL_DEEPSPEED=false \\\n",
            " --build-arg INSTALL_FLASHATTN=false \\\n",
            " --build-arg PIP_INDEX=https://pypi.org/simple \\\n",
            " -t llamafactory:latest .\n",
            "docker run -dit \\\n",
            " -v ./hf_cache:/root/.cache/huggingface \\\n",
            " -v ./ms_cache:/root/.cache/modelscope \\\n",
            " -v ./om_cache:/root/.cache/openmind \\\n",
            " -v ./data:/app/data \\\n",
            " -v ./output:/app/output \\\n",
            " -v ./saves:/app/saves \\\n",
            " -p 7860:7860 \\\n",
            " -p 8000:8000 \\\n",
            " --device /dev/kfd \\\n",
            " --device /dev/dri \\\n",
            " --shm-size 16G \\\n",
            " --name llamafactory \\\n",
            " llamafactory:latest\n",
            "\n",
            "docker exec -it llamafactory bash\n",
            "Details about volume\n",
            "hf_cache : Utilize Hugging Face cache on the host machine. Reassignable if a cache already exists in a different directory.\n",
            "ms_cache : Similar to Hugging Face cache but for ModelScope users.\n",
            "om_cache : Similar to Hugging Face cache but for Modelers users.\n",
            "data : Place datasets on this dir of the host machine so that they can be selected on LLaMA Board GUI.\n",
            "output : Set export dir to this location so that the merged result can be accessed directly on the host machine.\n",
            "Deploy with OpenAI-style API and vLLM\n",
            "API_PORT=8000 llamafactory-cli api examples/inference/llama3_vllm.yaml\n",
            "Tip Visit this page for API document.\n",
            "Examples: Image understanding | Function calling\n",
            "Download from ModelScope Hub\n",
            "If you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.\n",
            "export USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows\n",
            "Train the model by specifying a model ID of the ModelScope Hub as the model_name_or_path . You can find a full list of model IDs at ModelScope Hub , e.g., LLM-Research/Meta-Llama-3-8B-Instruct .\n",
            "Download from Modelers Hub\n",
            "You can also use Modelers Hub to download models and datasets.\n",
            "export USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows\n",
            "Train the model by specifying a model ID of the Modelers Hub as the model_name_or_path . You can find a full list of model IDs at Modelers Hub , e.g., TeleAI/TeleChat-7B-pt .\n",
            "Use W&B Logger\n",
            "To use Weights & Biases for logging experimental results, you need to add the following arguments to yaml files.\n",
            "report_to : wandb\n",
            "run_name : test_run # optional\n",
            "Set WANDB_API_KEY to your key when launching training tasks to log in with your W&B account.\n",
            "Use SwanLab Logger\n",
            "To use SwanLab for logging experimental results, you need to add the following arguments to yaml files.\n",
            "use_swanlab : true\n",
            "swanlab_run_name : test_run # optional\n",
            "When launching training tasks, you can log in to SwanLab in three ways:\n",
            "Add swanlab_api_key=<your_api_key> to the yaml file, and set it to your API key .\n",
            "Set the environment variable SWANLAB_API_KEY to your API key .\n",
            "Use the swanlab login command to complete the login.\n",
            "Projects using LLaMA Factory\n",
            "If you have a project that should be incorporated, please contact via email or create a pull request.\n",
            "Click to show\n",
            "Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. [arxiv]\n",
            "Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. [arxiv]\n",
            "Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. [arxiv]\n",
            "Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. [arxiv]\n",
            "Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. [arxiv]\n",
            "Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. [arxiv]\n",
            "Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. [arxiv]\n",
            "Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. [arxiv]\n",
            "Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. [arxiv]\n",
            "Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. [arxiv]\n",
            "Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. [arxiv]\n",
            "Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. [arxiv]\n",
            "Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. [arxiv]\n",
            "Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. [arxiv]\n",
            "Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. [arxiv]\n",
            "Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. [arxiv]\n",
            "Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. [arxiv]\n",
            "Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. [arxiv]\n",
            "Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. [arxiv]\n",
            "Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. [arxiv]\n",
            "Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. [arxiv]\n",
            "Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. [arxiv]\n",
            "Zhang et al. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling. 2024. [arxiv]\n",
            "Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. [arxiv]\n",
            "Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. [arxiv]\n",
            "Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. [arxiv]\n",
            "Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. [arxiv]\n",
            "Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. [arxiv]\n",
            "Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. [arxiv]\n",
            "Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. [arxiv]\n",
            "Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. [arxiv]\n",
            "Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. [arxiv]\n",
            "Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. [arxiv]\n",
            "Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. [arxiv]\n",
            "Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. [arxiv]\n",
            "Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. [arxiv]\n",
            "Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. [arxiv]\n",
            "Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. [arxiv]\n",
            "Dammu et al. \"They are uncultured\": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. [arxiv]\n",
            "Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. [arxiv]\n",
            "Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. [arxiv]\n",
            "Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. [arxiv]\n",
            "Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. [arxiv]\n",
            "Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. [paper]\n",
            "Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. [arxiv]\n",
            "Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. [arxiv]\n",
            "Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. [arxiv]\n",
            "Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. [arxiv]\n",
            "Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. [arxiv]\n",
            "Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. [arxiv]\n",
            "Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. [arxiv]\n",
            "Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. [arxiv]\n",
            "Zhu et al. Are Large Language Models Good Statisticians?. 2024. [arxiv]\n",
            "Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. [arxiv]\n",
            "Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. [arxiv]\n",
            "He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. [arxiv]\n",
            "Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. [arxiv]\n",
            "Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. [arxiv]\n",
            "Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. [arxiv]\n",
            "Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. [arxiv]\n",
            "Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. [arxiv]\n",
            "Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh's Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. [paper]\n",
            "Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. [arxiv]\n",
            "Yang et al. Financial Knowledge Large Language Model. 2024. [arxiv]\n",
            "Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. [arxiv]\n",
            "Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. [arxiv]\n",
            "Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. [arxiv]\n",
            "Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. [arxiv]\n",
            "Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. [paper]\n",
            "Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. [arxiv]\n",
            "Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. [arxiv]\n",
            "Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. [arxiv]\n",
            "Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. [arxiv]\n",
            "Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. [arxiv]\n",
            "Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. [paper]\n",
            "Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. [paper]\n",
            "Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. [paper]\n",
            "Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. [arxiv]\n",
            "Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. [arxiv]\n",
            "Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. [paper]\n",
            "Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. [arxiv]\n",
            "Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. [paper]\n",
            "StarWhisper : A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.\n",
            "DISC-LawLLM : A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.\n",
            "Sunsimiao : A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.\n",
            "CareGPT : A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.\n",
            "MachineMindset : A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.\n",
            "Luminia-13B-v3 : A large language model specialized in generate metadata for stable diffusion. [demo]\n",
            "Chinese-LLaVA-Med : A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.\n",
            "AutoRE : A document-level relation extraction system based on large language models.\n",
            "NVIDIA RTX AI Toolkit : SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.\n",
            "LazyLLM : An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.\n",
            "RAG-Retrieval : A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. [blog]\n",
            "360-LLaMA-Factory : A modified library that supports long sequence SFT & DPO using ring attention.\n",
            "License\n",
            "This repository is licensed under the Apache-2.0 License .\n",
            "Please follow the model licenses to use the corresponding model weights: Baichuan 2 / BLOOM / ChatGLM3 / Command R / DeepSeek / Falcon / Gemma / GLM-4 / GPT-2 / Granite / Index / InternLM2 / Llama / Llama 2 (LLaVA-1.5) / Llama 3 / MiniCPM / Mistral/Mixtral/Pixtral / OLMo / Phi-1.5/Phi-2 / Phi-3 / Qwen / Skywork / StarCoder 2 / TeleChat2 / XVERSE / Yi / Yi-1.5 / Yuan 2\n",
            "Citation\n",
            "If this work is helpful, please kindly cite as:\n",
            "@inproceedings { zheng2024llamafactory ,\n",
            " title = { LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models } ,\n",
            " author = { Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma } ,\n",
            " booktitle = { Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations) } ,\n",
            " address = { Bangkok, Thailand } ,\n",
            " publisher = { Association for Computational Linguistics } ,\n",
            " year = { 2024 } ,\n",
            " url = { http://arxiv.org/abs/2403.13372 } \n",
            "}\n",
            "Acknowledgement\n",
            "This repo benefits from PEFT , TRL , QLoRA and FastChat . Thanks for their wonderful works.\n",
            "Star History\n",
            "Footer\n",
            "© 2025 GitHub, Inc.\n",
            "Footer navigation\n",
            "Terms\n",
            "Privacy\n",
            "Security\n",
            "Status\n",
            "Docs\n",
            "Contact\n",
            "Manage cookies\n",
            "Do not share my personal information\n",
            "You canâ€™t perform that action at this time.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Repository ReadMe Extractor and Explainer\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mObservation: The README describes LLaMA-Factory as a tool for efficient fine-tuning of many large language models (LLMs).  It supports various models, training methods (including LoRA, QLoRA), and offers features like a GUI, Docker support, and integration with different logging tools.  It's highly relevant to the prompt because it directly addresses fine-tuning LLMs, including Llama 3.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mRead website content\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"website_url\\\": \\\"https://github.com/meta-llama/llama-recipes/blob/main/README.md\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "llama-recipes/README.md at main · meta-llama/llama-recipes · GitHub\n",
            "Skip to content\n",
            "Navigation Menu\n",
            "Toggle navigation\n",
            "Sign in\n",
            "Product\n",
            "GitHub Copilot\n",
            "Write better code with AI\n",
            "Security\n",
            "Find and fix vulnerabilities\n",
            "Actions\n",
            "Automate any workflow\n",
            "Codespaces\n",
            "Instant dev environments\n",
            "Issues\n",
            "Plan and track work\n",
            "Code Review\n",
            "Manage code changes\n",
            "Discussions\n",
            "Collaborate outside of code\n",
            "Code Search\n",
            "Find more, search less\n",
            "Explore\n",
            "All features\n",
            "Documentation\n",
            "GitHub Skills\n",
            "Blog\n",
            "Solutions\n",
            "By company size\n",
            "Enterprises\n",
            "Small and medium teams\n",
            "Startups\n",
            "By use case\n",
            "DevSecOps\n",
            "DevOps\n",
            "CI/CD\n",
            "View all use cases\n",
            "By industry\n",
            "Healthcare\n",
            "Financial services\n",
            "Manufacturing\n",
            "Government\n",
            "View all industries\n",
            "View all solutions\n",
            "Resources\n",
            "Topics\n",
            "AI\n",
            "DevOps\n",
            "Security\n",
            "Software Development\n",
            "View all\n",
            "Explore\n",
            "Learning Pathways\n",
            "White papers, Ebooks, Webinars\n",
            "Customer Stories\n",
            "Partners\n",
            "Executive Insights\n",
            "Open Source\n",
            "GitHub Sponsors\n",
            "Fund open source developers\n",
            "The ReadME Project\n",
            "GitHub community articles\n",
            "Repositories\n",
            "Topics\n",
            "Trending\n",
            "Collections\n",
            "Enterprise\n",
            "Enterprise platform\n",
            "AI-powered developer platform\n",
            "Available add-ons\n",
            "Advanced Security\n",
            "Enterprise-grade security features\n",
            "GitHub Copilot\n",
            "Enterprise-grade AI features\n",
            "Premium Support\n",
            "Enterprise-grade 24/7 support\n",
            "Pricing\n",
            "Search or jump to...\n",
            "Search code, repositories, users, issues, pull requests...\n",
            "Search\n",
            "Clear\n",
            "Search syntax tips\n",
            "Provide feedback\n",
            "We read every piece of feedback, and take your input very seriously.\n",
            "Include my email address so I can be contacted\n",
            "Cancel\n",
            "Submit feedback\n",
            "Saved searches\n",
            "Use saved searches to filter your results more quickly\n",
            "Name\n",
            "Query\n",
            "To see all available qualifiers, see our documentation .\n",
            "Cancel\n",
            "Create saved search\n",
            "Sign in\n",
            "Sign up\n",
            "Reseting focus\n",
            "You signed in with another tab or window. Reload to refresh your session.\n",
            "You signed out in another tab or window. Reload to refresh your session.\n",
            "You switched accounts on another tab or window. Reload to refresh your session.\n",
            "Dismiss alert\n",
            "meta-llama\n",
            "/\n",
            "llama-recipes\n",
            "Public\n",
            "Notifications\n",
            " You must be signed in to change notification settings\n",
            "Fork\n",
            " 2.3k\n",
            "Star\n",
            " 15.8k\n",
            "Code\n",
            "Issues\n",
            "34\n",
            "Pull requests\n",
            "36\n",
            "Actions\n",
            "Projects\n",
            "0\n",
            "Security\n",
            "Insights\n",
            "Additional navigation options\n",
            "Code\n",
            "Issues\n",
            "Pull requests\n",
            "Actions\n",
            "Projects\n",
            "Security\n",
            "Insights\n",
            "Files   main Breadcrumbs llama-recipes / README.md Blame Blame Latest commit   History History 182 lines (143 loc) · 9.93 KB   main Breadcrumbs llama-recipes / README.md Top File metadata and controls Preview Code Blame 182 lines (143 loc) · 9.93 KB Raw Llama Recipes: Examples to get started using the Llama models from Meta\n",
            "The 'llama-recipes' repository is a companion to the Meta Llama models. We support the latest version, Llama 3.2 Vision and Llama 3.2 Text , in this repository. This repository contains example scripts and notebooks to get started with the models in a variety of use-cases, including fine-tuning for domain adaptation and building LLM-based applications with Llama and other tools in the LLM ecosystem. The examples here use Llama locally, in the cloud, and on-prem.\n",
            "Tip Get started with Llama 3.2 with these new recipes:\n",
            "Finetune Llama 3.2 Vision\n",
            "Multimodal Inference with Llama 3.2 Vision\n",
            "Inference on Llama Guard 1B + Multimodal inference on Llama Guard 11B-Vision\n",
            "Note Llama 3.2 follows the same prompt template as Llama 3.1, with a new special token <|image|> representing the input image for the multimodal models.\n",
            "More details on the prompt templates for image reasoning, tool-calling and code interpreter can be found on the documentation website .\n",
            "Table of Contents\n",
            "Llama Recipes: Examples to get started using the Llama models from Meta\n",
            "Table of Contents\n",
            "Getting Started\n",
            "Prerequisites\n",
            "PyTorch Nightlies\n",
            "Installing\n",
            "Install with pip\n",
            "Install with optional dependencies\n",
            "Install from source\n",
            "Getting the Llama models\n",
            "Model conversion to Hugging Face\n",
            "Repository Organization\n",
            "recipes/\n",
            "src/\n",
            "Supported Features\n",
            "Contributing\n",
            "License\n",
            "Getting Started\n",
            "These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.\n",
            "Prerequisites\n",
            "PyTorch Nightlies\n",
            "If you want to use PyTorch nightlies instead of the stable release, go to this guide to retrieve the right --extra-index-url URL parameter for the pip install commands on your platform.\n",
            "Installing\n",
            "Llama-recipes provides a pip distribution for easy install and usage in other projects. Alternatively, it can be installed from source.\n",
            "Note Ensure you use the correct CUDA version (from nvidia-smi ) when installing the PyTorch wheels. Here we are using 11.8 as cu118 .\n",
            "H100 GPUs work better with CUDA >12.0\n",
            "Install with pip\n",
            "pip install llama-recipes\n",
            "Install with optional dependencies\n",
            "Llama-recipes offers the installation of optional packages. There are three optional dependency groups.\n",
            "To run the unit tests we can install the required dependencies with:\n",
            "pip install llama-recipes[tests]\n",
            "For the vLLM example we need additional requirements that can be installed with:\n",
            "pip install llama-recipes[vllm]\n",
            "To use the sensitive topics safety checker install with:\n",
            "pip install llama-recipes[auditnlg]\n",
            "Some recipes require the presence of langchain. To install the packages follow the recipe description or install with:\n",
            "pip install llama-recipes[langchain]\n",
            "Optional dependencies can also be combined with [option1,option2].\n",
            "Install from source\n",
            "To install from source e.g. for development use these commands. We're using hatchling as our build backend which requires an up-to-date pip as well as setuptools package.\n",
            "git clone git@github.com:meta-llama/llama-recipes.git\n",
            "cd llama-recipes\n",
            "pip install -U pip setuptools\n",
            "pip install -e .\n",
            "For development and contributing to llama-recipes please install all optional dependencies:\n",
            "git clone git@github.com:meta-llama/llama-recipes.git\n",
            "cd llama-recipes\n",
            "pip install -U pip setuptools\n",
            "pip install -e .[tests,auditnlg,vllm]\n",
            "Getting the Llama models\n",
            "You can find Llama models on Hugging Face hub here , where models with hf in the name are already converted to Hugging Face checkpoints so no further conversion is needed . The conversion step below is only for original model weights from Meta that are hosted on Hugging Face model hub as well.\n",
            "Model conversion to Hugging Face\n",
            "If you have the model checkpoints downloaded from the Meta website, you can convert it to the Hugging Face format with:\n",
            "# # Install Hugging Face Transformers from source \n",
            "pip freeze | grep transformers # # verify it is version 4.45.0 or higher\n",
            "git clone git@github.com:huggingface/transformers.git\n",
            " cd transformers\n",
            "pip install protobuf\n",
            "python src/transformers/models/llama/convert_llama_weights_to_hf.py \\\n",
            " --input_dir /path/to/downloaded/llama/weights --model_size 3B --output_dir /output/path\n",
            "Repository Organization\n",
            "Most of the code dealing with Llama usage is organized across 2 main folders: recipes/ and src/ .\n",
            "recipes/\n",
            "Contains examples organized in folders by topic:\n",
            "Subfolder\n",
            "Description\n",
            "quickstart\n",
            "The \"Hello World\" of using Llama, start here if you are new to using Llama.\n",
            "use_cases\n",
            "Scripts showing common applications of Meta Llama3\n",
            "3p_integrations\n",
            "Partner owned folder showing common applications of Meta Llama3\n",
            "responsible_ai\n",
            "Scripts to use PurpleLlama for safeguarding model outputs\n",
            "experimental\n",
            "Meta Llama implementations of experimental LLM techniques\n",
            "src/\n",
            "Contains modules which support the example recipes:\n",
            "Subfolder\n",
            "Description\n",
            "configs\n",
            "Contains the configuration files for PEFT methods, FSDP, Datasets, Weights & Biases experiment tracking.\n",
            "datasets\n",
            "Contains individual scripts for each dataset to download and process. Note\n",
            "inference\n",
            "Includes modules for inference for the fine-tuned models.\n",
            "model_checkpointing\n",
            "Contains FSDP checkpoint handlers.\n",
            "policies\n",
            "Contains FSDP scripts to provide different policies, such as mixed precision, transformer wrapping policy and activation checkpointing along with any precision optimizer (used for running FSDP with pure bf16 mode).\n",
            "utils\n",
            "Utility files for: - train_utils.py provides training/eval loop and more train utils. - dataset_utils.py to get preprocessed datasets. - config_utils.py to override the configs received from CLI. - fsdp_utils.py provides FSDP wrapping policy for PEFT methods. - memory_utils.py context manager to track different memory stats in train loop.\n",
            "Supported Features\n",
            "The recipes and modules in this repository support the following features:\n",
            "Feature\n",
            "HF support for inference\n",
            "✅\n",
            "HF support for finetuning\n",
            "✅\n",
            "PEFT\n",
            "✅\n",
            "Deferred initialization ( meta init)\n",
            "✅\n",
            "Low CPU mode for multi GPU\n",
            "✅\n",
            "Mixed precision\n",
            "✅\n",
            "Single node quantization\n",
            "✅\n",
            "Flash attention\n",
            "✅\n",
            "Activation checkpointing FSDP\n",
            "✅\n",
            "Hybrid Sharded Data Parallel (HSDP)\n",
            "✅\n",
            "Dataset packing & padding\n",
            "✅\n",
            "BF16 Optimizer (Pure BF16)\n",
            "✅\n",
            "Profiling & MFU tracking\n",
            "✅\n",
            "Gradient accumulation\n",
            "✅\n",
            "CPU offloading\n",
            "✅\n",
            "FSDP checkpoint conversion to HF for inference\n",
            "✅\n",
            "W&B experiment tracker\n",
            "✅\n",
            "Contributing\n",
            "Please read CONTRIBUTING.md for details on our code of conduct, and the process for submitting pull requests to us.\n",
            "License\n",
            "See the License file for Meta Llama 3.2 here and Acceptable Use Policy here\n",
            "See the License file for Meta Llama 3.1 here and Acceptable Use Policy here\n",
            "See the License file for Meta Llama 3 here and Acceptable Use Policy here\n",
            "See the License file for Meta Llama 2 here and Acceptable Use Policy here\n",
            "Footer\n",
            "© 2025 GitHub, Inc.\n",
            "Footer navigation\n",
            "Terms\n",
            "Privacy\n",
            "Security\n",
            "Status\n",
            "Docs\n",
            "Contact\n",
            "Manage cookies\n",
            "Do not share my personal information\n",
            "You can’t perform that action at this time.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Repository ReadMe Extractor and Explainer\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mObservation: This README describes `llama-recipes` as a collection of example scripts and notebooks for using Meta's Llama models.  It covers various use cases, including fine-tuning and building applications.  The repository is highly relevant because it provides practical examples using Llama, including Llama 3.2 Vision and Llama 3.2 Text models.  It's directly relevant to the prompt's request for fine-tuning code.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mRead website content\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"website_url\\\": \\\"https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning/blob/main/README.md\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "File not found · GitHub\n",
            "Skip to content\n",
            "Navigation Menu\n",
            "Toggle navigation\n",
            "Sign in\n",
            "Product\n",
            "GitHub Copilot\n",
            "Write better code with AI\n",
            "Security\n",
            "Find and fix vulnerabilities\n",
            "Actions\n",
            "Automate any workflow\n",
            "Codespaces\n",
            "Instant dev environments\n",
            "Issues\n",
            "Plan and track work\n",
            "Code Review\n",
            "Manage code changes\n",
            "Discussions\n",
            "Collaborate outside of code\n",
            "Code Search\n",
            "Find more, search less\n",
            "Explore\n",
            "All features\n",
            "Documentation\n",
            "GitHub Skills\n",
            "Blog\n",
            "Solutions\n",
            "By company size\n",
            "Enterprises\n",
            "Small and medium teams\n",
            "Startups\n",
            "By use case\n",
            "DevSecOps\n",
            "DevOps\n",
            "CI/CD\n",
            "View all use cases\n",
            "By industry\n",
            "Healthcare\n",
            "Financial services\n",
            "Manufacturing\n",
            "Government\n",
            "View all industries\n",
            "View all solutions\n",
            "Resources\n",
            "Topics\n",
            "AI\n",
            "DevOps\n",
            "Security\n",
            "Software Development\n",
            "View all\n",
            "Explore\n",
            "Learning Pathways\n",
            "White papers, Ebooks, Webinars\n",
            "Customer Stories\n",
            "Partners\n",
            "Executive Insights\n",
            "Open Source\n",
            "GitHub Sponsors\n",
            "Fund open source developers\n",
            "The ReadME Project\n",
            "GitHub community articles\n",
            "Repositories\n",
            "Topics\n",
            "Trending\n",
            "Collections\n",
            "Enterprise\n",
            "Enterprise platform\n",
            "AI-powered developer platform\n",
            "Available add-ons\n",
            "Advanced Security\n",
            "Enterprise-grade security features\n",
            "GitHub Copilot\n",
            "Enterprise-grade AI features\n",
            "Premium Support\n",
            "Enterprise-grade 24/7 support\n",
            "Pricing\n",
            "Search or jump to...\n",
            "Search code, repositories, users, issues, pull requests...\n",
            "Search\n",
            "Clear\n",
            "Search syntax tips\n",
            "Provide feedback\n",
            "We read every piece of feedback, and take your input very seriously.\n",
            "Include my email address so I can be contacted\n",
            "Cancel\n",
            "Submit feedback\n",
            "Saved searches\n",
            "Use saved searches to filter your results more quickly\n",
            "Name\n",
            "Query\n",
            "To see all available qualifiers, see our documentation .\n",
            "Cancel\n",
            "Create saved search\n",
            "Sign in\n",
            "Sign in to GitHub\n",
            "Username or email address\n",
            "Password\n",
            "Forgot password?\n",
            "or sign in with a passkey\n",
            "Sign up\n",
            "Reseting focus\n",
            "You signed in with another tab or window. Reload to refresh your session.\n",
            "You signed out in another tab or window. Reload to refresh your session.\n",
            "You switched accounts on another tab or window. Reload to refresh your session.\n",
            "Dismiss alert\n",
            "ruslanmv\n",
            "/\n",
            "Meta-Llama3-Fine-Tuning\n",
            "Public\n",
            "Notifications\n",
            " You must be signed in to change notification settings\n",
            "Fork\n",
            " 5\n",
            "Star\n",
            " 22\n",
            "Code\n",
            "Issues\n",
            "0\n",
            "Pull requests\n",
            "0\n",
            "Actions\n",
            "Projects\n",
            "0\n",
            "Security\n",
            "Insights\n",
            "Additional navigation options\n",
            "Code\n",
            "Issues\n",
            "Pull requests\n",
            "Actions\n",
            "Projects\n",
            "Security\n",
            "Insights\n",
            "Footer\n",
            "© 2025 GitHub, Inc.\n",
            "Footer navigation\n",
            "Terms\n",
            "Privacy\n",
            "Security\n",
            "Status\n",
            "Docs\n",
            "Contact\n",
            "Manage cookies\n",
            "Do not share my personal information\n",
            "You can’t perform that action at this time.\n",
            "\n",
            "\n",
            "\n",
            "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
            "\n",
            "Tool Name: Read website content\n",
            "Tool Arguments: {'website_url': {'description': 'Mandatory website url to read the file', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to read a website content.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, only one name of [Read website content], just the name, exactly as it's written.\n",
            "Action Input: the input to the action, just a simple python dictionary, enclosed in curly braces, using \" to wrap keys and values.\n",
            "Observation: the result of the action\n",
            "\n",
            "Once all necessary information is gathered:\n",
            "\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGitHub Repository ReadMe Extractor and Explainer\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "# GitHub Repository Summaries for Llama 3 Fine-tuning\n",
            "\n",
            "This document summarizes GitHub repositories relevant to fine-tuning Llama 3 models, categorized by relevance.  Note that ReadMe file availability varied.\n",
            "\n",
            "**Highly Relevant Links:**\n",
            "\n",
            "* **Repository Link:** [https://github.com/hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)\n",
            "    * **Category:** Highly Relevant\n",
            "    * **Explanation:** LLaMA-Factory is a comprehensive toolkit for efficient fine-tuning of various LLMs, including Llama 3.  It supports multiple training methods (LoRA, QLoRA, etc.), offers a user-friendly GUI, and provides Docker support for easy deployment.  Key features include support for a wide range of models and training approaches, making it highly versatile for fine-tuning tasks.\n",
            "\n",
            "* **Repository Link:** [https://github.com/meta-llama/llama-recipes](https://github.com/meta-llama/llama-recipes)\n",
            "    * **Category:** Highly Relevant\n",
            "    * **Explanation:** This repository offers example scripts and notebooks for using Meta's Llama models, including Llama 3.2 Vision and Llama 3.2 Text. It provides practical guidance on fine-tuning for domain adaptation and building LLM-based applications, covering local, cloud, and on-premise deployments.  The recipes demonstrate various techniques and integrations.\n",
            "\n",
            "\n",
            "**Moderately Relevant Links:**\n",
            "\n",
            "* **Repository Link:** [https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning](https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning)\n",
            "    * **Category:** Moderately Relevant\n",
            "    * **Explanation:** (Inferred from repository name) This repository likely focuses on fine-tuning Meta's Llama 3 models.  Further details are unavailable due to the absence of a README file.\n",
            "\n",
            "* **Repository Link:** [https://github.com/NVIDIA/workbench-example-llama3-finetune](https://github.com/NVIDIA/workbench-example-llama3-finetune)\n",
            "    * **Category:** Moderately Relevant\n",
            "    * **Explanation:** (Assumed based on name)  Likely provides examples of fine-tuning Llama 3 within NVIDIA's ecosystem.  A lack of README prevents a more precise description.\n",
            "\n",
            "* **Repository Link:** [https://github.com/unslothai/unsloth](https://github.com/unslothai/unsloth)\n",
            "    * **Category:** Moderately Relevant\n",
            "    * **Explanation:** (Assumed based on name and context) This repository likely provides tools or techniques for easier fine-tuning of LLMs, possibly including Llama 3.  Further details require inspection of the repository content.\n",
            "\n",
            "\n",
            "**Hidden Gems:**\n",
            "\n",
            "* **Repository Link:** [https://github.com/AIAnytime/Llama-3-ORPO-Fine-Tuning](https://github.com/AIAnytime/Llama-3-ORPO-Fine-Tuning)\n",
            "    * **Category:** Hidden Gem\n",
            "    * **Explanation:** (Inferred from repository name) This repository likely contains a niche implementation of fine-tuning Llama 3 using the ORPO method.  The lack of a README limits the description.\n",
            "\n",
            "* **Repository Link:** [https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning](https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning)\n",
            "    * **Category:** Hidden Gem\n",
            "    * **Explanation:** (Inferred from repository name) Similar to the above, this repository likely provides a specific, less widely known implementation of Llama 3 fine-tuning using ORPO.  More details are unavailable without a README.\n",
            "\n",
            "* **Other repositories:** Many other repositories might exist but lack visibility due to low star counts or limited documentation.\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAD7-AhGZ7Y7",
        "outputId": "04eb3c97-a121-41c9-d663-35864b6dfab8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# GitHub Repository Summaries for Llama 3 Fine-tuning\n",
            "\n",
            "This document summarizes GitHub repositories relevant to fine-tuning Llama 3 models, categorized by relevance.  Note that ReadMe file availability varied.\n",
            "\n",
            "**Highly Relevant Links:**\n",
            "\n",
            "* **Repository Link:** [https://github.com/hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)\n",
            "    * **Category:** Highly Relevant\n",
            "    * **Explanation:** LLaMA-Factory is a comprehensive toolkit for efficient fine-tuning of various LLMs, including Llama 3.  It supports multiple training methods (LoRA, QLoRA, etc.), offers a user-friendly GUI, and provides Docker support for easy deployment.  Key features include support for a wide range of models and training approaches, making it highly versatile for fine-tuning tasks.\n",
            "\n",
            "* **Repository Link:** [https://github.com/meta-llama/llama-recipes](https://github.com/meta-llama/llama-recipes)\n",
            "    * **Category:** Highly Relevant\n",
            "    * **Explanation:** This repository offers example scripts and notebooks for using Meta's Llama models, including Llama 3.2 Vision and Llama 3.2 Text. It provides practical guidance on fine-tuning for domain adaptation and building LLM-based applications, covering local, cloud, and on-premise deployments.  The recipes demonstrate various techniques and integrations.\n",
            "\n",
            "\n",
            "**Moderately Relevant Links:**\n",
            "\n",
            "* **Repository Link:** [https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning](https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning)\n",
            "    * **Category:** Moderately Relevant\n",
            "    * **Explanation:** (Inferred from repository name) This repository likely focuses on fine-tuning Meta's Llama 3 models.  Further details are unavailable due to the absence of a README file.\n",
            "\n",
            "* **Repository Link:** [https://github.com/NVIDIA/workbench-example-llama3-finetune](https://github.com/NVIDIA/workbench-example-llama3-finetune)\n",
            "    * **Category:** Moderately Relevant\n",
            "    * **Explanation:** (Assumed based on name)  Likely provides examples of fine-tuning Llama 3 within NVIDIA's ecosystem.  A lack of README prevents a more precise description.\n",
            "\n",
            "* **Repository Link:** [https://github.com/unslothai/unsloth](https://github.com/unslothai/unsloth)\n",
            "    * **Category:** Moderately Relevant\n",
            "    * **Explanation:** (Assumed based on name and context) This repository likely provides tools or techniques for easier fine-tuning of LLMs, possibly including Llama 3.  Further details require inspection of the repository content.\n",
            "\n",
            "\n",
            "**Hidden Gems:**\n",
            "\n",
            "* **Repository Link:** [https://github.com/AIAnytime/Llama-3-ORPO-Fine-Tuning](https://github.com/AIAnytime/Llama-3-ORPO-Fine-Tuning)\n",
            "    * **Category:** Hidden Gem\n",
            "    * **Explanation:** (Inferred from repository name) This repository likely contains a niche implementation of fine-tuning Llama 3 using the ORPO method.  The lack of a README limits the description.\n",
            "\n",
            "* **Repository Link:** [https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning](https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning)\n",
            "    * **Category:** Hidden Gem\n",
            "    * **Explanation:** (Inferred from repository name) Similar to the above, this repository likely provides a specific, less widely known implementation of Llama 3 fine-tuning using ORPO.  More details are unavailable without a README.\n",
            "\n",
            "* **Other repositories:** Many other repositories might exist but lack visibility due to low star counts or limited documentation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(\"Final_copy.md\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "tg8B_Jn0aTew",
        "outputId": "cb023a04-a65d-4c7d-d57a-9f0c27bb8088"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# GitHub Repository Summaries for Llama 3 Fine-tuning\n\nThis document summarizes GitHub repositories relevant to fine-tuning Llama 3 models, categorized by relevance.  Note that ReadMe file availability varied.\n\n**Highly Relevant Links:**\n\n* **Repository Link:** [https://github.com/hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)\n    * **Category:** Highly Relevant\n    * **Explanation:** LLaMA-Factory is a comprehensive toolkit for efficient fine-tuning of various LLMs, including Llama 3.  It supports multiple training methods (LoRA, QLoRA, etc.), offers a user-friendly GUI, and provides Docker support for easy deployment.  Key features include support for a wide range of models and training approaches, making it highly versatile for fine-tuning tasks.\n\n* **Repository Link:** [https://github.com/meta-llama/llama-recipes](https://github.com/meta-llama/llama-recipes)\n    * **Category:** Highly Relevant\n    * **Explanation:** This repository offers example scripts and notebooks for using Meta's Llama models, including Llama 3.2 Vision and Llama 3.2 Text. It provides practical guidance on fine-tuning for domain adaptation and building LLM-based applications, covering local, cloud, and on-premise deployments.  The recipes demonstrate various techniques and integrations.\n\n\n**Moderately Relevant Links:**\n\n* **Repository Link:** [https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning](https://github.com/ruslanmv/Meta-Llama3-Fine-Tuning)\n    * **Category:** Moderately Relevant\n    * **Explanation:** (Inferred from repository name) This repository likely focuses on fine-tuning Meta's Llama 3 models.  Further details are unavailable due to the absence of a README file.\n\n* **Repository Link:** [https://github.com/NVIDIA/workbench-example-llama3-finetune](https://github.com/NVIDIA/workbench-example-llama3-finetune)\n    * **Category:** Moderately Relevant\n    * **Explanation:** (Assumed based on name)  Likely provides examples of fine-tuning Llama 3 within NVIDIA's ecosystem.  A lack of README prevents a more precise description.\n\n* **Repository Link:** [https://github.com/unslothai/unsloth](https://github.com/unslothai/unsloth)\n    * **Category:** Moderately Relevant\n    * **Explanation:** (Assumed based on name and context) This repository likely provides tools or techniques for easier fine-tuning of LLMs, possibly including Llama 3.  Further details require inspection of the repository content.\n\n\n**Hidden Gems:**\n\n* **Repository Link:** [https://github.com/AIAnytime/Llama-3-ORPO-Fine-Tuning](https://github.com/AIAnytime/Llama-3-ORPO-Fine-Tuning)\n    * **Category:** Hidden Gem\n    * **Explanation:** (Inferred from repository name) This repository likely contains a niche implementation of fine-tuning Llama 3 using the ORPO method.  The lack of a README limits the description.\n\n* **Repository Link:** [https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning](https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning)\n    * **Category:** Hidden Gem\n    * **Explanation:** (Inferred from repository name) Similar to the above, this repository likely provides a specific, less widely known implementation of Llama 3 fine-tuning using ORPO.  More details are unavailable without a README.\n\n* **Other repositories:** Many other repositories might exist but lack visibility due to low star counts or limited documentation."
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ga-aSUAqogyV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}